\chapter{Efficient Incremental Search}
\label{chap:ibid}

In Chapter~\ref{chap:lazysp},
we introduced the Lazy Shortest Path (LazySP) algorithm,
which addresses domains with expensive edge weight functions
by interleaving the evaluation phase with a sequence of 
search queries using an existing pathfinding algorithm.
Because this inner search is conducted many times,
its efficiency is paramount.

Most approaches for reducing the computational cost of pathfinding
attempt to focus the search on a smaller subset of the graph.
We consider three classes of such techniques
(Figure~\ref{fig:ibid:intro-focus}):

\begin{marginfigure}[5cm]%
   \centering%
   \subfloat[Bidirectional search.]{%
      \centering %
      \includegraphics{build/ibid-intro-focus-bidirectional} %
   }%
   
   \subfloat[Heuristic search.]{%
      \centering %
      \includegraphics{build/ibid-intro-focus-heuristic} %
   }%
   
   \subfloat[Incremental search.]{%
      \centering %
      \includegraphics{build/ibid-intro-focus-incremental} %
   }%
   
   \caption{Illustrations of the three focusing techniques considered
      on a spatial pathfinding problem.}%
   \label{fig:ibid:intro-focus}
\end{marginfigure}

\begin{enumerate}
\item \emph{Bidirectional Search} -- A bidirectional algorithm
   conducts two concurrent searches,
   one from the source vertex $s$,
   and the other from the sink vertex $t$.
   Such searches are well-suited to roadmaps in ambient spaces that
   are high-dimensional and/or have
   obstacles situated close to the source/sink vertices.
\item \emph{Heuristic Search} -- A heuristic-informed algorithm
   exploits a sink-directed heuristic function over vertices to bias
   exploration in the direction of the sink vertex.
   A strong and admissible such heuristic can drastically speed the
   search,
   although the efficacy is reduced for weaker heuristics.
\item \emph{Incremental Search} -- An incremental algorithm
   is applied to a sequence of search queries on a graph whose
   edge weight function changes (partially) between queries.
   It endeavors to only consider the portion of its data structure
   affected by the changes.
\end{enumerate}

The principal contribution of this chapter is IBiD,
an algorithm which combines these three techniques into a single
algorithm
(Table~\ref{tab:ibid:alg-overview}).
While originally motivated for use with LazySP,
IBiD is broadly applicable to incremental search problems.

\paragraph{Chapter outline.}
In Section~\ref{sec:ibid:distance-functions},
we review distance functions and unidirectional methods.
Section~\ref{sec:ibid:bidirectional} reviews
bidirectional search methods.
In Section~\ref{sec:ibid:incremental},
we review incremental search
and introduce IBiD,
an algorithm which combines bidirectional and incremental search.
In Section~\ref{sec:ibid:heuristic},
we review heuristic search methods,
and discuss a heuristic-informed generalization of IBiD.
The chapter concludes with experimental results and implentation notes.

\begin{table}
   \centering
   \begin{tabular}{ccc}
      \toprule
      & Unidirectional & Bidirectional \\
      \midrule
      \addlinespace[0.2em]
      Complete
         & Dijkstra \citep{dijkstra1959anote}
         & Bidirectional Dijkstra \citep{luby1989bidijk} \\
      \addlinespace[-0.2em]
      \emph{(Heuristic)}
         & \emph{A* \citep{hart1968astar}}
         & \emph{Bidirectional A* \citep{ikeda1994betterroutes}} \\
      \addlinespace[0.3em]
      Incremental
         & DynamicSWSF-FP \citep{ramalingam1996dynamicswsffp}
         & {IBiD} \\
      \addlinespace[-0.2em]
      \emph{(Heuristic)}
         & \emph{Lifelong Planning A* \citep{koenig2004lpastar}}
         & \emph{Heuristic IBiD} \\
      \addlinespace[0.2em]
      \bottomrule
   \end{tabular}
   \caption{
      IBiD generalizes both the heuristic-informed
      bidirectional Dijkstra's search \citep{goldberg2005spexternalmemory}
      and DynamicSWSF-FP \citep{ramalingam1996dynamicswsffp}.
      There are a great many algorithms that we could place in each cell;
      we provide only a represetative choice in each.}
   \label{tab:ibid:alg-overview}
\end{table}

\section{Search via Distance Functions}
\label{sec:ibid:distance-functions}

\paragraph{Problem definition.}
The \emph{shortest path problem} on graphs has been extensively
studied over the past six decades.
Consider a directed graph $G = (V,E)$ and accompanying edge weight
function $w : E \rightarrow \mathbb{R}$,
with the length of a path equal to the sum of the weights of its
constituent edges.
\marginnote{
The single-pair problem is also called the \emph{two-terminal} or
\emph{point-to-point} problem.}
I include here a brief survey of algorithmic work on the
\emph{single-pair shortest path} (SPSP) problem,
where a path of minimal length is sought
between distinct source and target vertices
$s,t \in V$.
I also consider only graphs without negative-length cycles.
Note that we can also handle planning problems with multiple
start/goal configurations as an SPSP problem
as described in Section~\ref{subsec:roadmaps:planning-as-pathfinding}.

\paragraph{An example problem.}
\begin{marginfigure}%
   \centering%
   \begin{tikzpicture}
      \tikzset{>=latex} % arrow heads
      \node[inner sep=0pt,anchor=south west] {\includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/example-intro.png}};
      \coordinate (s) at (1.75,0.9);
      \coordinate (t) at (3.93,2.8);
      \node (slab) at (2.5,0.6) {$s$};
      \node (tlab) at (4.0,1.5) {$t$};
      \draw[->,thick] (slab) -- (s);
      \draw[->,thick] (tlab) -- (t);
   \end{tikzpicture}%
   \caption{A graph of the Northeast USA from the 9th DIMACS
      Implementation Challenge
      comprises 1,524,453 vertices and 3,868,020 directed edges.
      A shortest path problem from a source $s$ in New Jersey
      to a target $t$ outisde Boston
      will be used as an example.}%
   \label{fig:ibid:example-intro}%
\end{marginfigure}
We will carry forward an illustrative example problem from
the public dataset of the 9th DIMACS Implementation Challenge
\citep{demetrescuetal2006dimacs9}
(Northeast USA)
comprising an approximate road network,
using transit time as the edge weight function
(Figure~\ref{fig:ibid:example-intro}).
In this way,
a shortest path between a pair of sink and target locations
minimizes the total transit time between them.

\paragraph{Problem Settings.}
The single-pair problem has been extensively studied.
There are techniques that are particular to memory-constrained
settings \citep{kaindl1997biheurreconsidered}
or to settings where pre-computation is available
\citep{goldberg2007pointtopoint}.
While we do not focus on such settings,
the algorithm we propose is complementary to these techniques.

\subsection{Pathfinding via the Source Distance Function}

The pioneering pathfinding algorithms of the late 1950s address
a generalization of the SPSP problem called
the \emph{single-source} problem,
where shortest paths are calculated from $s$ to all vertices on
the graph.
They proceed by calculating the \emph{source distance function}
$d_s : V \rightarrow \mathbb{R}$,
which gives the length of the shortest path from $s$
to each vertex $v$.
In other words:
\marginnote{Once the distance function $d_s$ is computed,
a shortest path to any target $t$ can be generated trivially
by walking backwards to $s$ guided by $d_s$.}
\begin{equation}
   d_s(v) = \min_{p \in P_{sv}} \mbox{len}(p),
   \label{eqn:ibid-distance-function-global}
\end{equation}
where $P_{sv}$ is the set of all paths from $s$ to $v$.
Where no paths to $v$ exist,
we take $d_s(v) = \infty$.
Note that $d_s$ is only well-defined on graphs with no negative-length
cycles reachable from $s$.

\begin{marginfigure}%
   \centering%
   \includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/example-dijkstraall.png}%
   \caption{The distance function from the source vertex.}%
   \label{fig:ibid:example-distance-all}%
\end{marginfigure}

Importantly, $d_s$ can also be characterized locally by
\begin{equation}
   d_s(v) = 
   \left\{ \begin{array}{cl}
      0 & \mbox{if } v = s \\
      \displaystyle\min_{u \in \mbox{\scriptsize Pred}(v)} d_s(u) + w(u,v) & \mbox{otherwise,} \\
   \end{array} \right.
   \label{eqn:distance-function-char}
\end{equation}
where $\mbox{Pred}(v)$ yeilds the predecessor vertices
of $v$.
\marginnote{Note that
while the distance function $d_s$ necessarily satisfies
the equations (\ref{eqn:distance-function-char}),
they are not generally a sufficint condition;
if a reachable cycle of zero length exists,
(\ref{eqn:distance-function-char}) will not have a unique solution.}
The distance function is akin to the \emph{value function}
in more general decision problems addressed by dynamic programming.
The equations (\ref{eqn:distance-function-char})
are the \emph{Bellman equations} \citep{bellman1958routing},
which rely on the principle of optimality.
This characterization also follows implicitly from early results for
the all-pairs problem
\citep{shimbel1955communicationnets, beckmann1955transportation}.

\subsection{Approximating $d_s$ via Tensioned Estimates}
\label{subsec:ibid-tension}

How can we compute $d_s$ efficently over the graph?
Consider an approximation $\hat d_s$ of $d_s$ 
which satisfies the following properties:
\begin{equation}
   d_s(v) \leq \hat d_s(v)
   \mbox{ and }
   \hat d_s(s) = d_s(s) = 0.
   \label{eqn:ibid-relaxation-props}
\end{equation}
Further, for any approximation $\hat d_s$,
we can capture its violations of
(\ref{eqn:distance-function-char})
via the following labeling:
\begin{equation}
   \mbox{edge } (u,v) \mbox{ is \emph{tensioned}}
   \;\;\mbox{iff}\;\;
   \hat d_s(u) + w(u,v) < \hat d_s(v)
   \label{eqn:ibid-relaxation-tensioned}
\end{equation}

Suppose that we arrive at an approximation $\hat d_s$
satisfying (\ref{eqn:ibid-relaxation-props})
with no tensioned edges.
We can show that this estimate must be correct everywhere
(i.e. $\hat d_s(v) = d_s(v) \;\forall v$).
Consider any vertex $x$.
If $d_s(x) = \infty$,
then by (\ref{eqn:ibid-relaxation-props}) we must have that
$\hat d_s(x) = \infty$.
Otherwise,
by (\ref{eqn:ibid-distance-function-global}),
there exists a path $p$ of length $d_s(x)$;
consider this path.
The first vertex on $p$ is $s$,
and by (\ref{eqn:ibid-relaxation-props}),
$\hat d_s(s) = d_s(s)$.
For each edge $(u,v)$ on $p$ with $\hat d_s(u) = d_s(u)$,
we will show that if the edge is not tensioned,
then $\hat d_s(v) = d_s(v)$.
First, by (\ref{eqn:ibid-relaxation-props})
we have that $d_s(v) \leq \hat d_s(v)$.
Second,
since $(u,v)$ is not tensioned,
by (\ref{eqn:ibid-relaxation-tensioned})
we have that $\hat d_s(v) \leq \hat d_s(u) + w(u,v)$.
By (\ref{eqn:ibid-relaxation-props})
we can rewrite as
$\hat d_s(v) \leq d_s(u) + w(u,v)$,
which by definition of a shortest path,
we can write
$\hat d_s(v) \leq d_s(v)$.
Therefore $\hat d_s(v) = d_s(v)$,
and by induction along the path $p$,
we have that $\hat d_s(x) = d_s(x)$.

\subsection{Determining $d_s$ by Edge Relaxation}

We can initialize an approximation $\hat d_s$ so as to trivially
satisfy (\ref{eqn:distance-function-char}),
such as $\hat d_s(v) = \infty \;\forall v \neq s$.
But how can we improve the approximation in order to
calculate $d_s$?
The principal technique relies on the principle of
\emph{relaxation}
as described by Ford \citep{ford1955networkflowtheory}.
An algorithm can iteratively select tensioned edges and
relax them by setting
$\hat d_s(v) \leftarrow \hat d_s(u) + w(u,v)$.
It can be shown that applying this process arbitrarily
maintains the properties in (\ref{eqn:distance-function-char}).

It can be further shown that for a finite graph,
the number of edge relaxations needed is also finite.
The well-known Bellman-Ford method
\citep{shimbel1955communicationnets, bellman1958routing,
moore1959spmaze}
cycles through all edges repeatedly,
relaxing all tensioned edges found
(at most $|V|-1$ repetitions are sufficient for convergence).

\subsection{Exploiting A Better Relaxation Ordering}

The need for multiple cycles of Bellman-Ford stems from the fact
that each edge may need to be relaxed several times.
Consider the vertices $a \rightarrow b \rightarrow c$,
with edges $ab$ and $bc$ both in tension;
if $bc$ is relaxed before $ab$,
then $bc$ will need to be relaxed a second time.
This occurrs because relaxing an edge changes the
$\hat d_s$-value of the target vertex,
which may newly tension downstream edges.

We can exploit our intution to order relaxations from source to sink
in the special case where $w \geq 0$
(note that this requirement is stronger than requiring no reachable
negative-length cycles).
In this case,
let $\hat d_s'$ be the smallest value $\hat d_s(u)$
for any edge $uv$ currently in tension.
Then we can show that any vertex $v$ with $\hat d_s(v) \leq \hat d_s'$
has $\hat d_s(v) = d_s(v)$.

The proof proceeds as follows.
First, if $\hat d_s' = \infty$,
then no edges can be in tension,
and so $\hat d_s = d_s$ everywhere
as shown in Section~\ref{subsec:ibid-tension}.
Otherwise,
suppose that $\hat d_s(x) \neq d_s(x)$
for some vertex $x$ with $\hat d_s(x) \leq \hat d_s'$.
By (\ref{eqn:ibid-relaxation-props}),
it would have to be that $d_s(x) < \hat d_s(x)$.
Consider a true shortest path $p$ from $s$ to $x$;
by (\ref{eqn:ibid-relaxation-props})
such a path exists and has finite length $d_s(x)$.
By (\ref{eqn:ibid-relaxation-props}),
we have that $d_s(s) = \hat d_s(s) = 0$
(and so $s$ and $x$ must be distinct).
Let $(u,v)$ be the first edge along $p$ such that
$d_s(u) = \hat d_s(u)$
but $d_s(v) < \hat d_s(v)$.
Since $p$ is a shortest path,
edge $(u,v)$ must therefore be in tension.
Since $w \geq 0$,
it must be that $d_s(u) \leq d_s(x)$;
further, since $d_s(u) = \hat d_s(u)$,
$d_s(x) < \hat d_s(x)$,
and $\hat d_s(x) \leq \hat d_s'$
it must be that $\hat d_s(u) < \hat d_s'$.
But then edge $(u,v)$ is in tension with lower $\hat d_s(u)$!
This contradiction implies that every vertex $x$
with $\hat d_s(x) \leq \hat d_s'$
must have $\hat d_s(x) = d_s(x)$.

\begin{marginfigure}
   \centering
   \includegraphics{build/ibid-dijkstra-trust}
   \caption{Tensioned edge trust region
      for $w \geq 0$.
      Contours are of the current estimate $\hat d_s$.
      Currently tensioned edges are bold and dotted.}
\end{marginfigure}

As a result,
a given value $\hat d_s'$ creates a region of vertices
with values $\hat d_s(x) \leq \hat d_s'$ that are known to be
accurate.
This confers two distinct advantages when designing an algorithm.
First,
all tensioned edges $(u,v)$ with $\hat d_s(u) = \hat d_s'$
(of which there must be at least one if any edges are in tension)
can be relaxed immediately,
and will never be retensioned.
This is exactly the order imposed by the OPEN list in Dijkstra's
algorithm \citep{dijkstra1959anote}.
Second,
if a path is sought only a particular destination vertex $t$,
the algorithm can be terminated once
$\hat d_s(t) \leq \hat d_s'$,
since at that point the true distance to $t$ will be known valid.

\begin{marginfigure}%
   \centering%
   \includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/example-dijkstra.png}%
   \caption{Dijkstra's algorithm computes the start distance function
      $d_s$ to solve the example shortest path problem.
      Darker vertices have smaller $d$-values.
      The algorithm stops upon reaching the target vertex $t$
      after expanding 1,290,820 vertices.}%
   \label{fig:ibid:example-distance}%
\end{marginfigure}

\section{Incremental Search}
\label{sec:ibid:incremental}

How can we adapt the relaxation approach to the incremental setting?
And how can we recover the original algorithm from the more general one?

This stuff is more modern (1996, 2004).

A review is here: \citep{eppstein1999dynamic},
\citep{demetrescu2010dynamic}.

Talk about how this is centrally a restatement of the Dijktsra's ordering.
Bring in the invariant.

DynamicSWSF-FP \citep{ramalingam1996dynamicswsffp}.

How about this: \citep{frigioni2000dynamicsp}.

Revisit Bellman equation.

The central idea is that the search maintains the following invariant.
Note that this is a basic restatement of the distance function
ordering that underlies Dijkstra's algorithm.

\begin{invariant}
If $w$ is everywhere positive and $k_{\ms{min}}$ is the key of
the minimal inconsistent vertex,
then all vertices with key $k(v) < k_{\ms{min}}$ is consistent
and correct.
\end{invariant}

\begin{marginfigure}%
   \centering%
   \subfloat[Initial search]{%
      \centering%
      \includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/example-incuni-0.png}%
   }
   
   \subfloat[Replan search]{%
      \centering%
      \includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/example-incuni-1.png}%
   }%
   \caption{Initial search: 1,287,897 expansions.
      Replan: 391,122 expansions.}%
   %\label{fig:ibid:example-bidirectional}%
\end{marginfigure}

\subsection{Incremental Bidirectional Search: The Algorithm}

\begin{marginfigure}%
   \centering%
   \subfloat[Initial search]{%
      \centering%
      \includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/example-incbi-0.png}%
   }
   
   \subfloat[Replan search]{%
      \centering%
      \includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/example-incbi-1.png}%
   }%
   \caption{Initial search: 1,181,616 expansions.
      Replan: 262,422 expansions.}%
   %\label{fig:ibid:example-bidirectional}%
\end{marginfigure}




\section{Bidirectional Search}
\label{sec:ibid:bidirectional}

One prominent technique for minimizing pathfinding computation for
single-pair problems
is bidirectional search.
In a bidirectional algorithm,
the distance $d_t$ to the target is calculated in a growing region
around the target vertex $t$
concurrently with the conventional source distance $d_s$ around $s$
(Figure~\ref{fig:ibid:example-bidirectional}).
Loosely speaking,
the search can terminate with a shortest path
once the two regions intersect.
The savings relative to a unidirectional search grow with the problem's
branching factor.
For roadmap graphs embedded in an ambient space,
this branching factor can be linear or exponential in the space's
dimension.
\begin{marginfigure}%
   \centering%
   \includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/example-bidijkstra.png}%
   \caption{The bidirectional Dijkatra's algorithm
      computes $d_s$ around the source vertex
      and $d_t$ around the target vertex.
      Darker vertices have smaller $d$-values in their respective
      regions.
      The algorithm terminates after expanding a total of
      1,178,200 vertices using distance to balance expansions.}%
   \label{fig:ibid:example-bidirectional}%
\end{marginfigure}

The first bidirectional algorithm
was proposed by Dantzig \citep{dantzig1963linearprogramming},
and the first precisely described algorithm was presented by
Nicholson \citep{nicholson1966shortest}.

Implementation of a sound and efficient algorithm
turns on two important questions:
(a) how to balance expansions from the two directions of the search,
and (b) when and how to terminate with a shortest path.

\paragraph{Balancing Directions}
The general bidirectional algorithm leaves open the strategy
used to balance the progression of the two search directions.
Options based on alternating \citep{dantzig1963linearprogramming},
or selecting the direction with the smaller {\sc Open} distance
\citep{nicholson1966shortest}
or {\sc Open} (and finite) set cardinality
\citep{pohl1969bidirectional}
have been proposed.
Note that while some literature asserts that
these can be interleaved arbitrarily,
termination of the algorithm requires that each direction
be expanded at least once.
Our example problems use the balanced distance criterion.

\subsection{Termination Conditions}
\label{sec:ibid:bidirectional-termination}

What happens upon an encounter between the forward and reverse searches?
Goldberg \citep{goldberg2005spexternalmemory}
discusses the correct termination condition for the 
Bidirectional Dijkstra algorithm.

A correct termination condition is surprisingly subtle,%
\marginnote{There were early incorrect attempts at a sound
termination condition
\citep{berge1965programminggamestransportation}.}
with several correct variations proposed
\citep{nicholson1966shortest, dreyfus1969appraisalsp,
pohl1969bidirectional, goldberg2005spexternalmemory}.
The difficulty stems from the fact that the first vertex to be
{\sc Closed} by the searches in both directions
need not lie on the shortest path
(Figure~\ref{fig:ibid:bidirectional-termination-issue}).

Key point, reason about edges!

See Algorithm~\ref{alg:ibid:bidirectional-termination}.

\begin{algorithm}[t]
   \caption{Bidirectional Termination Condition}
   \label{alg:ibid:bidirectional-termination}
   \begin{algorithmic}[1]
      \State On $u$ expanded in the foward search
         with $v$ already expanded in the backward search,
   \end{algorithmic}
\end{algorithm}

\begin{marginfigure}
   \centering
   \begin{tikzpicture}
      \tikzset{>=latex} % arrow heads
      \node[draw,circle,inner sep=1.5pt] (s) at (0,0) {};
      \node[draw,circle,inner sep=1.5pt] (a) at (1.5,0) {};
      \node[draw,circle,inner sep=1.5pt] (b) at (3.0,0) {};
      \node[draw,circle,inner sep=1.5pt] (t) at (4.5,0) {};
      \node[draw,circle,inner sep=1.5pt] (c) at (2.25,0.8) {};
      \draw[->] (s) -- (a) node[midway,fill=white,circle,inner sep=1pt] {3};
      \draw[->] (a) -- (b) node[midway,fill=white,circle,inner sep=1pt] {3};
      \draw[->] (b) -- (t) node[midway,fill=white,circle,inner sep=1pt] {3};
      \draw[->] (a) -- (c) node[midway,fill=white,circle,inner sep=1pt] {2};
      \draw[->] (c) -- (b) node[midway,fill=white,circle,inner sep=1pt] {2};
      \node[below=0.05cm of s] {$s$};
      \node[below=0.05cm of a] {$a$};
      \node[below=0.05cm of b] {$b$};
      \node[below=0.05cm of t] {$t$};
      \node[above=0.05cm of c] {$c$};
   \end{tikzpicture}
   \caption{Simple illustration of a problem case for terminating
      a bidirectional search.
      With a balanced distance criterion,
      $c$ will be the first vertex expanded in both directions,
      but it does not lie on the shortest path.}
   \label{fig:ibid:bidirectional-termination-issue}
\end{marginfigure}

\subsection{IBiD}

The main outline of IBiD is given in Algorithm~\ref{alg:ibid}.
IBiD conducts two independent DynamicSWSF-FP searches
(Algorithm~\ref{alg:ibid-two-dynamicswsffps}).

\begin{algorithm}[t]
   \caption{IBiD Outline}
   \label{alg:ibid}
   \begin{algorithmic}[1]
      \Procedure {Main} {\,}
         \State $\mbox{\sc InitializeSource}(); \; \mbox{\sc InitializeTarget}()$
         \State $Q_c \gets \emptyset$
            \Comment $\mbox{ key for } (u,v): d_s(u) + w(u,v) + d_t(v)$
         \Loop
            \While {not $\mbox{\sc TerminationCondition}()$}
               \If {$Q_s.\mbox{TopKey} < Q_t.\mbox{TopKey}$}
                     \Comment prioritize arbitrarily
                  \State $\mbox{\sc ProcessSourceQueue}(u)$
               \Else
                  \State $\mbox{\sc ProcessTargetQueue}(u)$
               \EndIf
               \State Ensure $(u,v) \in Q_c$ iff
                  $u \neq Q_s$, $v \neq Q_t$, key $\neq \infty$
            \EndWhile
            \State $(u_c,v_c) \gets Q_c.\mbox{Top}$
            \State $\pi \gets
               ( \mbox{walk } d_s \mbox{ from } u_c \mbox{ to } s )
               \cup
               ( \mbox{walk } d_t \mbox{ from } v_c \mbox{ to } t )$
            \State wait for edges $(u,v) \in E_{\ms{delta}}$ with changed weights $w(u,v)$
            \State $\mbox{\sc NotifyWeightChanges}(E_{\ms{delta}})$
         \EndLoop
      \EndProcedure
      \Function {TerminationCondition} {\,}
         \State $(u_c,v_c) \gets Q_c.\mbox{TopKey}$
            \Comment return False if $Q_c$ empty
         \If {$Q_s.\mbox{TopKey} + Q_t.\mbox{TopKey} < d_s(u_c) + w(u_c,v_c) + d_t(v_c)$}
            \State \Return False
         \EndIf
         \If {$Q_s.\mbox{TopKey} < d_s(u_c)$
               \mbox{\bf or} $Q_t.\mbox{TopKey} < d_t(v_c)$}
            \State \Return False
         \EndIf
         \State \Return True
      \EndFunction
      \Procedure {NotifyWeightChanges} {$E_{\ms{delta}}$}
         \ForAll {$(u,v) \in E_{\ms{delta}}$}
            \State $\mbox{\sc UpdateSourceDistance}(v)$
            \State $\mbox{\sc UpdateTargetDistance}(u)$
         \EndFor
         \State Ensure $(u,v) \in Q_c$ iff
            $u \neq Q_s$, $v \neq Q_t$, key $\neq \infty$
      \EndProcedure
   \end{algorithmic}
\end{algorithm}

{\floatevery{algorithm}{\setlength\hsize{16.85cm}}
\begin{algorithm}[t]
   \caption{As a bidirectional algorithm,
      IBiD conducts two independent DynamicSWSF-FP searches,
      one computing distance from the source vertex,
      and the other computing distance to the target vertex.}
   \label{alg:ibid-two-dynamicswsffps}
   \begin{minipage}[t]{8.2cm}
      \begin{algorithmic}[1]
         \Procedure {InitializeSource} {\,\!}
            \ForAll {$v \in V$}
               \State $d_s(v) \gets \infty; \;\; r_s(v) \gets \infty$
            \EndFor
            \State $r_s(s) \gets 0$
            \State $Q_s \gets \{ s \}$
               \Comment $\mbox{ key for } v: \min\big(r_s(v),d_s(v)\big)$
            \State $\mbox{\sc ProcessSourceQueue}()$
         \EndProcedure
         \Procedure {UpdateSourceDistance} {$v$}
            \If {$v \neq s$}
               \State $r_s(v) \gets \displaystyle\min_{u \in \mbox{\scriptsize Pred}(v)}
                  \big( d_s(u) + w(u,v) \big)$
            \EndIf
            \State Ensure $v \in Q_s$ iff $d_s(v) \neq r_s(v)$
         \EndProcedure
         \Procedure {ProcessSourceQueue} {\,\!}
            \State $u \gets Q_s.\mbox{Pop}()$
            \If {$r_s(u) < d_s(u)$}
                  \Comment over-consistent
               \State $d_s(u) \gets r_s(u)$
               \ForAll {$v \in \mbox{Succ}(u)$}
                  \State $\mbox{\sc UpdateSourceDistance}(v)$
               \EndFor
            \Else
                  \Comment under-consistent
               \State $d_s(u) \gets \infty$
               \ForAll {$v \in \mbox{Succ}(u) \cup u$}
                  \State $\mbox{\sc UpdateSourceDistance}(v)$
               \EndFor
            \EndIf
         \EndProcedure
         \algstore{ibid-two-dynamicswsffps}
      \end{algorithmic}
   \end{minipage}
   \quad
   \begin{minipage}[t]{8.2cm}
      \begin{algorithmic}[1]
         \algrestore{ibid-two-dynamicswsffps}
         \Procedure {InitializeTarget} {\,\!}
            \ForAll {$v \in V$}
               \State $d_t(v) \gets \infty; \;\; r_t(v) \gets \infty$
            \EndFor
            \State $r_t(t) \gets 0$
            \State $Q_t \gets \{ t \}$
               \Comment $\mbox{ key for } v: \min\big(r_t(v),d_t(v)\big)$
            \State $\mbox{\sc ProcessTargetQueue}()$
         \EndProcedure
         \Procedure {UpdateTargetDistance} {$u$}
            \If {$u \neq t$}
               \State $r_t(u) \gets \displaystyle\min_{v \in \mbox{\scriptsize Succ}(u)}
                  \big( w(u,v) + d_t(v) \big)$
            \EndIf
            \State Ensure $u \in Q_t$ iff $d_t(u) \neq r_t(u)$
         \EndProcedure
         \Procedure {ProcessTargetQueue} {\,\!}
            \State $v \gets Q_t.\mbox{Pop}()$
            \If {$r_t(v) < d_t(v)$}
                  \Comment over-consistent
               \State $d_t(v) \gets r_t(v)$
               \ForAll {$u \in \mbox{Pred}(v)$}
                  \State $\mbox{\sc UpdateTargetDistance}(u)$
               \EndFor
            \Else
                  \Comment under-consistent
               \State $d_t(v) \gets \infty$
               \ForAll {$u \in \mbox{Pred}(v) \cup v$}
                  \State $\mbox{\sc UpdateTargetDistance}(u)$
               \EndFor
            \EndIf
         \EndProcedure
      \end{algorithmic}
   \end{minipage}
\end{algorithm}
} % floatevery width adjustment

\section{Heuristic Search}
\label{sec:ibid:heuristic}

Heuristic methods such as the Graph Traverser
\citep{doran1966graphtraverser} were originally
applied to pathfinding problems in order to find non-optimal
solutions more economically.
These unidirectional methods proceed similarly to Dijkstra's algorithm,
but instead of prioritizing {\sc Open} vertices
based on their source distance $d_s$,
they use a target-directed heuristic function $h_t$.
Hart, Nilsson, and Raphael \citep{hart1968astar} discovered that
these approaches can be combined ($d_s + h_t$) to yield
an admissible algorithm (A*) for the shortest-path problem,
as long as $h_t$ meets certain conditions.

\paragraph{Example problem.}
\begin{marginfigure}%
   \centering%
   \includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/example-astar.png}%
   \caption{A* search.
      532,880 expansions.}%
   \label{fig:ibid:example-astar}%
\end{marginfigure}
See Figure~\ref{fig:ibid:example-astar}.
For the purpose of calculating vertex heuristics,
geographic coordinates were projected onto a 2D plane using the
scale at the midpoint latitude ($41.25^\circ$)
resulting in a projecting error of less than 0.3\%.
The maximum transit speed is 30.11 m/s.

Attempts to provide a bidirectional algorithm which incorporates
heuristics generally take one of three approaches.
\cdnote{I need to deep-dive here to write this correctly.}

First,
front-to-front methods
could evaluate the heuristic between all pairs in the two
{\sc Open} sets.
Expensive.

Second,
perform two heuristic-informed searches,
and account for the connection problem via a complex
termination condition.
Not necessarily efficient.
(Pohl cites Berge?)
Missile analogy.

Third,
waste (same heuristic function).

Concept of waste \citep{pohl1969bidirectional}.
I think this subsumes A*.

Talk about the 94 paper \citep{ikeda1994betterroutes}
expressing A* as a search on
the waste graph.

As a potential function.
Also Goldberg \citep{goldberg2005spexternalmemory}.

To integrate: \citep{dechter1984bfsastaropt}.

\paragraph{Example problem.}
\begin{marginfigure}%
   \centering%
   \includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/example-heurbidijkstra.png}%
   \caption{Bidirectional A* search.
      515,588 expansions.}%
   \label{fig:ibid:example-heurbidijkstra}%
\end{marginfigure}
See Figure~\ref{fig:ibid:example-heurbidijkstra}.

\subsection{The Zero-Weight Problem}

Talk about how a perfect potential leads to zero waste,
which breaks incremental search.
This motivates the lexocraphically sorted key approach.

\subsection{Incremental Heuristic Search}

Apply waste to incremental search to get
incremental heuristic search.

Lifelong Planning A* \citep{koenig2004lpastar}.

\section{Other Stuff}

\subsection{Examples}

See Figure~\ref{fig:incbi-lpastar-fig1-heurchange}
and Figure~\ref{fig:incbi-lpastar-fig1}.

\begin{figure}
   \centering%
   
   \includegraphics{build/incbi-lpastar-fig1/lpastar-heurnone-original}%
   \;\;%
   \includegraphics{build/incbi-lpastar-fig1/incbi-heurnone-original}%
   
   \vspace{0.2cm}
   
   \includegraphics{build/incbi-lpastar-fig1/lpastar-heurhalf-original}%
   \;\;%
   \includegraphics{build/incbi-lpastar-fig1/incbi-heurhalf-original}%
   
   \vspace{0.2cm}
   
   \includegraphics{build/incbi-lpastar-fig1/lpastar-heurfull-original}%
   \;\;%
   \includegraphics{build/incbi-lpastar-fig1/incbi-heurfull-original}%
   
   \caption{Illustration of behavior of IBiD on a single
      (non-incremental) shortest path problem.
      At left, IBiD uses the unidirectional start-side expansion
      strategy.
      At right, IBiD uses the bidirectional distance-balanaced
      expansion strategy.
      Start and goal heuristic functions are available;
      the unidirectional search uses a potential function based
      on the goal heuristic,
      and the bidirectional search a potential function using
      the average heuristic.
      IBiD is run with three different potential function weights:
      0.0 (top), 0.5 (middle), and 1.0 (bottom).
      IBiD therefore preforms equivalently to
      Dijkstra's algorithm (top-left),
      Bidirectional Dijkstra's (top-right),
      A* (bottom-left),
      and Bidirectional A* (bottom-right).}
   \label{fig:incbi-lpastar-fig1-heurchange}
\end{figure}

\begin{figure}
   \centering%
   
   \includegraphics{build/incbi-lpastar-fig1/lpastar-heurfull-original}%
   \;\;%
   \includegraphics{build/incbi-lpastar-fig1/lpastar-heurfull-changed}%
   
   \vspace{0.2cm}
   
   \includegraphics{build/incbi-lpastar-fig1/incbi-heurfull-original}%
   \;\;%
   \includegraphics{build/incbi-lpastar-fig1/incbi-heurfull-changed}%
   
   \caption{IBiD with only source-side expansions and a goal-side
      heuristic (top) proceeds identically to Lifelong Planning A*,
      performing 37 expansions on the original world (left)
      followed by 18 expansions over 14 vertices on the chanced
      world (right).
      IBiD with distance-balanced expansions and an average
      potential (bottom)
      performs 30 expansions on the original world
      followed by 18 expansions over 15 vertices on the changed
      world.}
   \label{fig:incbi-lpastar-fig1}
\end{figure}

\begin{figure*}
   \centering%
   
   \begin{tabular}{ccc}
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/pgoalnone-balfwd.png}\\556,209 expansions}
      &
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/pavgnone-baldist.png}\\319,938 expansions}
      &
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/pavgnone-balcard.png}\\281,413 expansions}
      \vspace{0.3cm}
      \\
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/pgoalhalf-balfwd.png}\\297,414 expansions}
      &
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/pavghalf-baldist.png}\\206,625 expansions}
      &
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/pavghalf-balcard.png}\\178,929 expansions}
      \vspace{0.3cm}
      \\
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/pgoalfull-balfwd.png}\\82,915 expansions}
      &
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/pavgfull-baldist.png}\\95,759 expansions}
      &
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/singleshot/pavgfull-balcard.png}\\69,218 expansions}
      \vspace{0.5cm}
   \end{tabular}
   
   \caption{Comparison between various heuristic strengths and
      balancing strageties on a single-pair road network problem.
      A path with shortest transit time is sought.
      The heuristic strength varies from no heuristic (top)
      to a full-strength heuristic (bottom).
      At left, a foward-only balancer is used, so that the
      top-left is equivalent to Dijkstra's algorithm,
      and the bottom-left is equivalent to A*.
      The middle column uses a balanced distance strategy.
      The right column uses a balanced cardinality strategy.}
   \label{fig:incbi-road-ne}
\end{figure*}

\subsection{LazySP Selector Experiments}

\begin{figure}
   \centering
   \includegraphics{build/incbi-sq/all-even}
   \caption{Across a selection of articulated robot planning instances,
      using the Even edge selector.
      Algorithms are
      \protect\tikz{\protect\node[fill=black!30,draw=black,postaction={pattern=north west lines}]{};}\;LPA*,
      \protect\tikz{\protect\node[fill=black!20,draw=black]{};}\;IBiD,
      and \protect\tikz{\protect\node[fill=black!30,draw=black,postaction={pattern=north east lines}]{};}\;Reverse LPA*.
      Results shown are cumulative search time.
      }
\end{figure}

\begin{figure}
   \centering
   \includegraphics{build/incbi-road-ne/stats}
   \caption{Road network incremental results.
      Algorithms are
      \protect\tikz{\protect\node[fill=black!30,draw=black,postaction={pattern=north west lines}]{};}\;LPA*,
      \protect\tikz{\protect\node[fill=black!20,draw=black]{};}\;IBiD,
      and \protect\tikz{\protect\node[fill=black!30,draw=black,postaction={pattern=north east lines}]{};}\;Reverse LPA*.
      }
\end{figure}

\begin{figure}
   \centering
   \includegraphics{build/incbi-sq/herbbin0}
   
   \includegraphics{build/incbi-sq/herbbin0-lambda}
   \caption{Problem: \texttt{herbbin0}.
      Lines are:
      \protect\tikz{\protect\draw[thick] (0,0) -- (0.15,0.15);} no heuristic,
      \protect\tikz{\protect\draw[densely dashed] (0,0) -- (0.15,0.15);} start heuristic,
      \protect\tikz{\protect\draw[densely dashdotted] (0,0) -- (0.15,0.15);} avg heuristic,
      \protect\tikz{\protect\draw[densely dotted] (0,0) -- (0.15,0.15);} goal heuristic.
      }
\end{figure}

\begin{figure*}
   \centering
   \includegraphics{build/incbi-sq/herbbookshelf0}
   \includegraphics{build/incbi-sq/herbbookshelf1nom}
   
   \includegraphics{build/incbi-sq/herbbookshelf0-lambda}
   \includegraphics{build/incbi-sq/herbbookshelf1nom-lambda}
   \caption{Problems: \texttt{herbbookshelf0} (left), texttt{herbbookshelf1nom} (right).}
\end{figure*}

\begin{figure*}
   \centering
   \includegraphics{build/incbi-sq/workcellef}
   \includegraphics{build/incbi-sq/workcellij}
   
   \includegraphics{build/incbi-sq/workcellef-lambda}
   \includegraphics{build/incbi-sq/workcellij-lambda}
   \caption{Problems: \texttt{workcellef} (left), \texttt{workcellij} (right).}
\end{figure*}

\subsection{Implementation Details}

Other implementations:
\citep{alberts1998softwaredynamicgraph}.
