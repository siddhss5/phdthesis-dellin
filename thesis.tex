\documentclass[nobib]{tufte-book}

\usepackage{standalone}

\usepackage{calc}

%\usepackage[bookmarks=true]{hyperref}
\usepackage{hyperref}

% symbols
\usepackage{amsmath} % assumes amsmath package installed
\usepackage{amssymb} % for \square

% non-italicized math subscripts
\newcommand{\ms}[1]{\mbox{\scriptsize #1}}

% from http://tex.stackexchange.com/a/5255
\DeclareMathOperator*{\argmin}{arg\,min}

% algorithm stuff
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

\usepackage{array}
\usepackage{graphicx}

% the subcaption package is incompatible with tufte-book
% the caption package is incomatible with tufte-book
% the caption=false option to subfig prevents it from loading caption
\usepackage[caption=false]{subfig}
\usepackage{float} % for side-by-side figures?
% http://tex.stackexchange.com/a/95357

\usepackage{setspace}

\floatstyle{plain}
\newfloat{genericfloat}{h}{gflt}

\usepackage{pgfplots}
\usepackage{tikz}
\usetikzlibrary{arrows,backgrounds,calc,patterns,positioning,shapes,decorations.pathmorphing}

% from http://tex.stackexchange.com/a/103691
% taken from manual
\makeatletter
\pgfdeclareshape{document}{
\inheritsavedanchors[from=rectangle] % this is nearly a rectangle
\inheritanchorborder[from=rectangle]
\inheritanchor[from=rectangle]{center}
\inheritanchor[from=rectangle]{north}
\inheritanchor[from=rectangle]{south}
\inheritanchor[from=rectangle]{west}
\inheritanchor[from=rectangle]{east}
% ... and possibly more
\backgroundpath{% this is new
% store lower right in xa/ya and upper right in xb/yb
\southwest \pgf@xa=\pgf@x \pgf@ya=\pgf@y
\northeast \pgf@xb=\pgf@x \pgf@yb=\pgf@y
% compute corner of ‘‘flipped page’’
\pgf@xc=\pgf@xb \advance\pgf@xc by-4pt % this should be a parameter
\pgf@yc=\pgf@yb \advance\pgf@yc by-4pt
% construct main path
\pgfpathmoveto{\pgfpoint{\pgf@xa}{\pgf@ya}}
\pgfpathlineto{\pgfpoint{\pgf@xa}{\pgf@yb}}
\pgfpathlineto{\pgfpoint{\pgf@xc}{\pgf@yb}}
\pgfpathlineto{\pgfpoint{\pgf@xb}{\pgf@yc}}
\pgfpathlineto{\pgfpoint{\pgf@xb}{\pgf@ya}}
\pgfpathclose
% add little corner
\pgfpathmoveto{\pgfpoint{\pgf@xc}{\pgf@yb}}
\pgfpathlineto{\pgfpoint{\pgf@xc}{\pgf@yc}}
\pgfpathlineto{\pgfpoint{\pgf@xb}{\pgf@yc}}
\pgfpathlineto{\pgfpoint{\pgf@xc}{\pgf@yc}}
}
}
\makeatother

% pretty tables
\usepackage{multirow}
\usepackage{booktabs}

% see http://tex.stackexchange.com/a/19678
\newcommand{\specialcell}[2][c]{\begin{tabular}[#1]{@{}c@{}}#2\end{tabular}}

% custom title page
\usepackage{titling}

% for adjustwidth
\usepackage{changepage}

% include \paragraph as numbered
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{1} % 3

\usepackage{color}

%\def\hidenotes{}
% list of commenters
\newcommand{\ssnote}[1]{{\xxnote{SS}{red}{#1}}}
\newcommand{\cdnote}[1]{{\xxnote{CD}{blue}{#1}}}
\newcommand{\mknote}[1]{{\xxnote{MK}{green}{#1}}}
% implement conditional notes (turn on/off with \hidenotes above)
\newcommand{\xxnote}[3]{}
\ifx\hidenotes\undefined
  \renewcommand{\xxnote}[3]{\color{#2}{#1: #3}}
\fi

% wide page for side by side figures, tables, etc
% see http://tex.stackexchange.com/a/154766
\newlength{\offsetpage}
\setlength{\offsetpage}{1.5in}
\newenvironment{widepage}
   {\begin{adjustwidth}{-\offsetpage}{-\offsetpage}%
    \addtolength{\textwidth}{2\offsetpage}}%
{\end{adjustwidth}}

% theorems
\newtheorem{invariant}{Invariant}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}{Proposition}
\newtheorem{lemma}{Lemma}
% from http://www.maths.tcd.ie/~dwilkins/LaTeXPrimer/Theorems.html
\newenvironment{proof}[1][Proof]{\begin{trivlist}
   \item[\hskip \labelsep {\bfseries #1}]}{\hfill$\square$\end{trivlist}}

\title{Efficient Manipulation Task Planning via\\
   Reuse-Informed Optimization of Planning Effort
   \cdnote{need new title!}}
\author{Christopher M. Dellin}
\date{\today}
%\date{March 28, 2015}

\renewcommand{\maketitlehooka}{
\begin{fullwidth}
}

\renewcommand{\maketitlehookd}{
\begin{center}
\vspace{0.7in}
The Robotics Institute\\
Carnegie Mellon University\\
Pittsburgh, PA 15213\\
\vspace{0.7in}
\textbf{Thesis Committee:}\\
Siddhartha Srinivasa, CMU RI (Chair)\\
Anthony Stentz, CMU RI\\
Maxim Likhachev, CMU RI\\
Lydia Kavraki, Rice University\\
%\vspace{0.7in}
%\emph{Submitted in partial fulfillment of the requirements\\
%for the degree of Doctor of Philosophy.}
\end{center}
\end{fullwidth}
}

\begin{document}

\maketitle

%\begin{abstract}
\begin{fullwidth}
\begin{adjustwidth}{1in}{1in}

{\LARGE \emph{Abstract}}

\vspace{0.2in}

\cdnote{todo: rewrite abstract}

In order to assist humans
with dangerous or menial tasks,
autonomous robots will need to
act under significant time and energy constraints.
At task time,
the amount of effort a robot spends planning directly
detracts from its total performance.
Manipulation tasks, however, present challenges
to efficient motion planning.
They are often tightly coupled --
while moving an object can be decomposed into
steps (reach, grasp, transfer, release),
each step requires choices (e.g. which grasp),
and committing to a bad choice
can render subsequent steps difficult;
this encourages longer planning horizons.
However,
an articulated robot
situated within a geometrically complex and dynamic environment
induces a high-dimensional configuration space
in which it is expensive to test for valid paths.
And since multi-step plans
require paths in changing valid subsets of configuration space,
it is difficult to reuse computation across steps
or maintain caches between tasks.

We focus on a motion planning approach for coupled multi-step
manipulation problems that is efficient over the entire task
(including both planning and execution).
We contend that the problem's cost structure
favors explicit handling of
both graph representation and task effort optimization,
and propose a graph search algorithm which captures these insights
given a model of planning effort.
We offer methods for roadmap construction
which seek to balance completeness with efficiency at task time.
We then unify previous work examining configuration space structure of
related problems (e.g. multi-step manipulation)
into a general set-theoretic formulation
which suggests a planning effort model
to be exploited by our roadmap search algorithm,
yielding a motion planner which
efficiently reuses computation between queries.
We also present a task planner
that maps a task decomposition into queries to our motion planner.
Our insights yield complementary components
which, taken together,
constitute an efficient approach to planning manipulation tasks.

This thesis proposes a heavy emphasis on experimental evaluation
of the individual constituent algorithms
and the approach as a whole.
We will compare against
state-of-the-art task and motion planners
on multiple robotic platforms,
in applications from home table clearing
to remote disaster response.
We also provide open-source implementations of our algorithms.

\end{adjustwidth}
\end{fullwidth}
%\end{abstract}

\tableofcontents

\chapter{Introduction}

Outline of contributions:
\begin{itemize}
\item LazySP (Chapter~\ref{chap:lazysp})
\item IBID (Chapter~\ref{chap:ibid})
\item LEMUR (Chapter~\ref{chap:lemur})
\item Planning with C-Space Families (Chapter~\ref{chap:family})
\end{itemize}

\chapter{Fast Pathfinding on Graphs via Lazy Evaluation}
\label{chap:lazysp}

{\bf Selectors.
Edge-equivalence.}

While the shortest path problem has myriad applications,
the computational efficiency of suitable algorithms
depends intimately on the underlying problem domain.
In this paper,
we focus on domains where evaluating the edge weight function
dominates algorithm running time.
%\ajnote{I don't find out what this paper's contribution is
%until the 3rd sentence ... start stronger!}
Inspired by approaches in robotic motion planning,
we define and investigate the \emph{Lazy Shortest Path} class of
algorithms which is differentiated by the choice of
an \emph{edge selector} function.
We show that several algorithms in the literature are equivalent to
this lazy algorithm for appropriate choice of this selector.
Further, we propose various novel selectors inspired by
sampling and statistical mechanics,
and find that these selectors outperform
existing algorithms on a set of example problems.

\section{Introduction}

\begin{figure}
\centering
\begin{tikzpicture}
   \tikzset{>=latex} % arrow heads
   %\draw[step=1cm,black!10,very thin] (0,0) grid (8,4);
   \node[draw,align=center,minimum height=1.0cm,thick]
      at (2.5,2.5) {Graph\\$G=(V,E)$};
   \node[draw,align=center,minimum height=1.0cm,thick]
      at (5.5,2.5) {Weight Function\\$w:E \rightarrow [0,+\infty]$};
   \node[draw,align=center,minimum height=1.0cm,minimum width=3cm,thick]
      (alg) at (4,1) {Shortest Path\\Algorithm};
   \node[draw,align=center,shape=document,minimum width=1.5cm,ultra thin]
      (query) at (1,1) {Query $u$};
   \node[draw,align=center,shape=document,minimum width=1.5cm,ultra thin]
      (path) at (7,1) {Path $p^*$};
   \draw[->] (3,2) -- (3,1.5);
   \draw[->] (5,2) -- (5,1.5);
   \draw[->] (query.east) -- (alg.west);
   \draw[->] (alg.east) -- (path.west);
\end{tikzpicture}
\caption{While solving a shortest path query,
   a shortest path algorithm incurs computation cost from three sources:
   examining the structure of the graph $G$,
   evaluating the edge weight function $w$,
   and maintaining internal data structures.}
\label{fig:sp-intro}
\end{figure}

Graphs provide a powerful abstraction
capable of representing problems in a wide variety of domains
from computer networking to puzzle solving
to robotic motion planning.
%\ajnote{Way too vague and general -- disconnected from second sentence.
%Maybe mention ``standard problems'' on graphs.}
In particular,
many important problems can be captured
as \emph{shortest path problems} (Figure~\ref{fig:sp-intro}),
wherein a path $p^*$ of minimal length is desired
between two query vertices through a graph $G$
with respect to an edge weight function $w$.
%As such,
%a large number of algorithms have been proposed in the literature
%for solving shortest path problems efficiently.

Despite the expansive applicability of this single abstraction,
there exist a wide variety of algorithms in the literature
for solving the shortest path problem efficiently.
%\ajnote{You say ``despite'' but the second part seems to follow from
%the first.
%There are many solutions because there are many problems.}
This is because the measure of computational efficiency,
and therefore the correct choice of algorithm,
is inextricably tied to the underlying problem domain.

The computational costs incurred by an algorithm
can be broadly categorized into three sources
corresponding to the blocks in Figure~\ref{fig:sp-intro}.
One such source consists of queries on the structure
of the graph $G$ itself.
The most commonly discussed such operation,
\emph{expanding} a vertex (determining its successors),
is especially fundamental
%\ajnote{especially costly?}
when the graph is represented implicitly,
e.g. for domains with large graphs
such as the 15-puzzle or Rubik's cube.
It is with respect to vertex expansions
that A* \citep{hart1968astar} is optimally efficient.

A second source of computational cost consists of maintaining
ordered data structures inside the algorithm itself,
which is especially important for problems with large branching
factors.
For such domains,
approaches such as partial expansion \citep{yoshizumi2000peastar}
or iterative deepening \citep{korf1985idastar}
significantly reduce the number of vertices generated and stored
by either selectively filtering surplus vertices from the frontier,
or by not storing the frontier at all.

The third source of computational cost arises not from reasoning
over the structure of $G$,
but instead from evaluating the edge weight function $w$
(i.e. we treat discovering an out-edge and determining its weight
separately).
Consider for example the problem of articulated robotic motion planning
using roadmap methods \citep{kavrakietal1996prm}.
While these graphs are often quite small
(fewer than $10^5$ vertices),
determining the weight of each edge requires performing many
collision and distance computations for the complex geometry
of the robot and environment,
resulting in planning times of multiple seconds to find a path.

In this paper,
we consider problem domains in which evaluating the edge weight
function $w$ dominates algorithm running time
and investigate the following research question:
\begin{quote}
How can we minimize the number of edges we need to evaluate
to answer shortest-path queries?
\end{quote}

We make three primary contributions.
First,
inspired by lazy collision checking techniques from 
robotic motion planning \citep{bohlin2000lazyprm},
we formulate a class of shortest-path algorithms 
that is well-suited to problem domains with expensive edge evaluations.
Second,
we show that several existing algorithms in the literature
can be expressed as special cases of this algorithm.
Third,
we show that the extensibility afforded by the algorithm allows for
novel edge evaluation strategies,
which can outperform existing algorithms
over a set of example problems.

\section{Lazy Shortest Path Algorithm}

We describe a lazy approach to finding short paths
which is well-suited to domains with
expensive edge evaluations.

\subsection{Problem Definition}

A path $p$ in a graph $G = (V,E)$
is composed of a sequence of adjacent edges 
connecting two endpoint vertices.
Given an edge weight function
$w : E \rightarrow [0,+\infty]$,
the length of the path with respect to $w$ is then:
\begin{equation}
   \mbox{len}(p, w) = \sum_{e \in p} w(e).
\end{equation}
Given a single-pair planning query
$u: (v_{\ms{start}}, v_{\ms{goal}})$
inducing a set of satisfying paths $P_u$,
the \emph{shortest-path problem} is:
\begin{equation}
   p^* = \argmin_{p \, \in \, P_u} \mbox{len}(p, w).
   \label{eqn:objective}
\end{equation}

A shortest-path algorithm computes $p^*$
given $(G, u, w)$.
Many such algorithms have been proposed
to efficiently accommodate a wide array of underlying problem domains.
%(outlined in Section~\ref{sec:discussion}).
The well-known principle of best-first search (BFS)
is commonly employed to select vertices for expansion
so as to minimize such expansions while guaranteeing optimality.
Since we seek to minimize edge evaluations,
we apply BFS to the question of selecting candidate paths in
$G$ for evaluation.
The resulting algorithm, Lazy Shortest Path (LazySP),
is presented in Algorithm~\ref{alg:lazy-outline},
and can be applied to graphs defined implicitly or explicitly.

%\cdnote{To Sidd: You might not like this paragraph -- but I feel like
%going directly from the problem definition to the algorithm doesn't
%connect to the rationale strongly enough without it.
%What do you think?}

\subsection{The Algorithm}

\begin{algorithm}[t]
\caption{Lazy Shortest Path (LazySP)}
\label{alg:lazy-outline}
\begin{algorithmic}[1]
\Function {\textsc{LazyShortestPath}}{$G, u, w, w_{\ms{est}}$}
\State $E_{\ms{eval}} \leftarrow \emptyset$ %\Comment Initialize evaluated edges to empty
\State $w_{\ms{lazy}}(e) \leftarrow w_{\ms{est}}(e) \quad \forall e \in E$ %\Comment Initialize lazy edge weights to estimate (inexpensive)
\Loop
   \State $p_{\ms{candidate}} \leftarrow
      \mbox{\sc ShortestPath}(G, u, w_{\ms{lazy}})$ %\Comment Compute the shortest path with lazy edge weights
      \label{line:lazy-outline-shortestpath}
   \If {$p_{\ms{candidate}} \subseteq E_{\ms{eval}}$} %\Comment If all edges on path have already been evaluated,
      \State \Return $p_{\ms{candidate}}$ %\Comment path returned is provably optimal
   \EndIf
   \State $E_{\ms{selected}} \leftarrow  \mbox{\sc Selector}(G, p_{\ms{candidate}})$ %\Comment Select edges on path to process
   \label{line:lazy-outline-chooseedges} 
   \For {$e \in E_{\ms{selected}} \setminus E_{\ms{eval}}$} %\Comment For all unevaluated selected edges
      \State $w_{\ms{lazy}}(e) \leftarrow w(e)$ \Comment Evaluate (expensive)
      \State $E_{\ms{eval}} \leftarrow E_{\ms{eval}} \cup e$ %\Comment Add to evaluated edge set
   \EndFor
\EndLoop
\EndFunction
\end{algorithmic}
\end{algorithm}

We track evaluated edges with the set $E_{\ms{eval}}$.
We are given an estimator function $w_{\ms{est}}$ of the true edge weight $w$.
This estimator is inexpensive to compute
(e.g. edge length or even $0$).
We then define a \emph{lazy} weight function $w_{\ms{lazy}}$
which returns the
true weight of an evaluated edge and otherwise
uses the inexpensive estimator $w_{\ms{est}}$.

At each iteration of the search,
the algorithm uses $w_{\ms{lazy}}$ to compute a candidate path
$p_{\ms{candidate}}$
by calling an existing solver \textsc{ShortestPath}
(note that this invocation requires no evaluations of $w$).
Once a candidate path has been found,
it is returned if it is fully evaluated.
Otherwise,
an \emph{edge selector} is employed which selects
graph edge(s) for evaluation.
The true weights of these edges are then evaluated
(incurring the requisite computational cost),
and the algorithm repeats.

%\subsection{Theoretical Properties}

LazySP is complete and optimal
(proofs in the appendix):

\begin{theorem}[Completeness of LazySP]
If the graph $G$ is finite,
\textsc{ShortestPath} is complete,
and the set $E_{\ms{selected}}$
returned by \textsc{Selector}
returns at least one unevaluated edge on $p_{\ms{candidate}}$,
then \textsc{LazyShortestPath} is complete.
\label{thm:lazy-completeness}
\end{theorem}

\begin{theorem}[Optimality of LazySP]
If $w_{\ms{est}}$ is chosen such that
$w_{\ms{est}}(e) \leq \epsilon \, w(e)$ for some parameter
$\epsilon \geq 1$ and
\textsc{LazyShortestPath} terminates
with some path $p_{\ms{ret}}$,
then $\mbox{len}(p_{\ms{ret}}, w) \leq \epsilon \, \ell^*$
with $\ell^*$ the length of an optimal path.
\label{thm:lazy-optimality}
\end{theorem}

The optimality of LazySP depends on the admissibility of
$w_{\ms{est}}$
in the same way that the optimality of A* depends on
the admissibility of its goal heuristic $h$.
Theorem~\ref{thm:lazy-optimality} establishes the general
bounded suboptimality of LazySP
w.r.t. the inflation parameter $\epsilon$.
While our theoretical results (e.g. equivalences)
hold for any choice of $\epsilon$,
for clarity our examples and experimental results
focus on cases with $\epsilon = 1$.

\subsection{The Edge Selector: Key to Efficiency}

\begin{algorithm}[t]
\caption{Various Simple LazySP Edge Selectors}
\begin{algorithmic}[1]
\Function {\textsc{SelectExpand}}{$G, p_{\ms{candidate}}$}
   \State $e_{\ms{first}} \leftarrow$ first unevaluated $e \in p_{\ms{candidate}}$
   \State $v_{\ms{frontier}} \leftarrow G.\mbox{source}(e_{\ms{first}})$
   \State $E_{\ms{selected}} \leftarrow G.\mbox{out\_edges}(v_{\ms{frontier}})$
   \State \Return $E_{\ms{selected}}$
\EndFunction
\vspace{0.02in}
\Function {\textsc{SelectForward}}{$G, p_{\ms{candidate}}$}
   \State \Return $\{ \mbox{first unevaluated } e \in p_{\ms{candidate}} \}$
\EndFunction
\vspace{0.02in}
\Function {\textsc{SelectReverse}}{$G, p_{\ms{candidate}}$}
   \State \Return $\{ \mbox{last unevaluated } e \in p_{\ms{candidate}} \}$
\EndFunction
\vspace{0.02in}
\Function {\textsc{SelectAlternate}}{$G, p_{\ms{candidate}}$}
   \If {LazySP iteration number is odd}
      \State \Return $\{ \mbox{first unevaluated } e \in p_{\ms{candidate}} \}$
   \Else
      \State \Return $\{ \mbox{last unevaluated } e \in p_{\ms{candidate}} \}$
   \EndIf
\EndFunction
\vspace{0.02in}
\Function {\textsc{SelectBisection}}{$G, p_{\ms{candidate}}$}
   \State \Return $\left\{ \begin{array}{ll}
      \mbox{unevaluated } e \in p_{\ms{candidate}} \\
      \mbox{furthest from nearest evaluated edge}
      \end{array} \right\}$
\EndFunction
\end{algorithmic}
\label{alg:simple-selectors}
\end{algorithm}

%The algorithm purposely leaves undecided
%the edge evaulation selector codified in
%\textsc{Selector} (line~\ref{line:lazy-outline-chooseedges}),
%and therefore describes a class of algorithms
%differentiated by the choice of this selector.
%This paper discusses particular choices.

The LazySP algorithm exhibits a rough similarity to optimal
replanning algorithms such as
D* \citep{stentz1994dstar}
which plan a sequence of shortest paths for a mobile robot
as new edge weights are discovered during its traverse.
D* treats edge changes
passively as an aspect of the problem setting
(e.g. a sensor with limited range).

The key difference is that our problem setting treats 
edge evaluations as an active choice that can be exploited.
While any choice of edge selector that meets the conditions above
will lead to an algorithm that is complete and optimal,
its \emph{efficiency} is dictated by the choice of this
selector.
This motivates the theoretical and empirical investigation of different
edge selectors in this paper.

\textbf{Simple selectors.}
We codify five common strategies in
Algorithm~\ref{alg:simple-selectors}.
The Expand selector captures the edge weights that are evaluated
during a conventional vertex expansion.
The selector identifies the first unevaluated edge
$e_{\ms{first}}$ on the candidate path,
and considers the source vertex of this edge a \emph{frontier} vertex.
It then selects all out-edges of this frontier vertex
for evaluation.
The Forward and Reverse selectors select the first and last
unevaluated edge on the candidate path, respectively
(note that Forward returns a subset of Expand).

The Alternate selector simply alternates between Forward
and Reverse on each iteration.
This can be motivated by both bidirectional search algorithms
as well as motion planning algorithms such as
RRT-Connect \citep{kuffner2000rrtconnect}
which tend to perform well w.r.t. state evaluations.

The Bisection selector
chooses among those unevaluated edges
the one furthest from an evaluated edge on the candidate path.
This selector is roughly analogous to the collision checking strategy
employed by the Lazy PRM \citep{bohlin2000lazyprm}
as applied to our problem on abstract graphs.

In the following section,
we demonstrate that instances of LazySP using simple selectors
yield equivalent results to existing vertex algorithms.
We then discuss two more sophisticated
selectors motivated by weight function sampling
and statistical mechanics.

% prob-box2d00-halton-roots16
% fwd:34 partall:22 rev:24 fwdexpand:77
% bisect:25 worlddist:22 alt:23 partsimple:22
\begin{figure*}[t!]%
   \!\!%
   \subfloat[Expand(77)]{%
      \centering%
      \begin{tikzpicture}
         \node at (0,-0.0) {\includegraphics{build/lazysp-example-1/alg-fwdexpand-after5}};
         \node at (0,-2.5) {\includegraphics{build/lazysp-example-1/alg-fwdexpand-end}};
         \node at (0,-4.8) {\includegraphics{build/lazysp-example-1/alg-fwdexpand-path-bars}};
      \end{tikzpicture}%
   }%
   \!\!%
   \subfloat[Forward(34)]{%
      \centering%
      \begin{tikzpicture}
         \node at (0,-0.0) {\includegraphics{build/lazysp-example-1/alg-fwd-after5}};
         \node at (0,-2.5) {\includegraphics{build/lazysp-example-1/alg-fwd-end}};
         \node at (0,-4.8) {\includegraphics{build/lazysp-example-1/alg-fwd-path-bars}};
      \end{tikzpicture}%
   }%
   \!\!%
   \subfloat[Reverse(24)]{%
      \centering%
      \begin{tikzpicture}
         \node at (0,-0.0) {\includegraphics{build/lazysp-example-1/alg-rev-after5}};
         \node at (0,-2.5) {\includegraphics{build/lazysp-example-1/alg-rev-end}};
         \node at (0,-4.8) {\includegraphics{build/lazysp-example-1/alg-rev-path-bars}};
      \end{tikzpicture}%
   }%
   \!\!%
   \subfloat[Alternate(23)]{%
      \centering%
      \begin{tikzpicture}
         \node at (0,-0.0) {\includegraphics{build/lazysp-example-1/alg-alt-after5}};
         \node at (0,-2.5) {\includegraphics{build/lazysp-example-1/alg-alt-end}};
         \node at (0,-4.8) {\includegraphics{build/lazysp-example-1/alg-alt-path-bars}};
      \end{tikzpicture}%
   }%
   \!\!%
   \subfloat[Bisect(25)]{%
      \centering%
      \begin{tikzpicture}
         \node at (0,-0.0) {\includegraphics{build/lazysp-example-1/alg-bisect-after5}};
         \node at (0,-2.5) {\includegraphics{build/lazysp-example-1/alg-bisect-end}};
         \node at (0,-4.8) {\includegraphics{build/lazysp-example-1/alg-bisect-path-bars}};
      \end{tikzpicture}%
   }%
   \!\!%
   \subfloat[WeightSamp(22)]{%
      \centering%
      \begin{tikzpicture}
         \node at (0,-0.0) {\includegraphics{build/lazysp-example-1/alg-worlddist1000-after5}};
         \node at (0,-2.5) {\includegraphics{build/lazysp-example-1/alg-worlddist1000-end}};
         \node at (0,-4.8) {\includegraphics{build/lazysp-example-1/alg-worlddist1000-path-bars}};
      \end{tikzpicture}%
   }%
   \!\!%
   \subfloat[Partition(22)]{%
      \centering%
      \begin{tikzpicture}
         \node at (0,-0.0) {\includegraphics{build/lazysp-example-1/alg-partall-after5}};
         \node at (0,-2.5) {\includegraphics{build/lazysp-example-1/alg-partall-end}};
         \node at (0,-4.8) {\includegraphics{build/lazysp-example-1/alg-partall-path-bars}};
      \end{tikzpicture}%
   }%
   \caption[lazysp snapshots]{Snapshots of the LazySP algorithm using each edge selector
      discussed in this paper on the same obstacle roadmap graph problem,
      with start (\protect\tikz[baseline=-0.5ex]{\protect\node[circle,fill=blue,inner sep=1pt]{};})
      and goal (\protect\tikz[baseline=-0.5ex]{\protect\node[circle,fill=green,inner sep=1pt]{};}).
      At top, the algorithms after evaluating five edges
      (evaluated edges labeled as
      \protect\tikz{\protect\draw[very thick] (0,0) -- (0.15,0.15);}  valid
      or \protect\tikz{\protect\draw[very thick,red] (0,0) -- (0.15,0.15);} invalid).
      At middle, the final set of evaluated edges.
      At bottom, for each unique path considered from left to right,
      the number of edges on the path that are
      \protect\tikz{\protect\node[fill=green!40!white,draw=black]{};}\;already evaluated,
      \protect\tikz{\protect\node[fill=green!70!black,draw=black]{};}\;evaluated and valid,
      \protect\tikz{\protect\node[fill=red!70!black,draw=black]{};}\;evaluated and invalid,
      and \protect\tikz{\protect\node[fill=black!10!white,draw=black]{};}\;unevaluated.
      The total number of edges evaluated is noted in brackets.
      Note that the scale on the Expand plot has been adjusted
      because the selector evaluates many edges not on the candidate
      path at each iteration.
      }
   \label{fig:snapshots}
\end{figure*}

\section{Edge Equivalence to A* Variants}

\begin{table}
   \centering
   {\small%
   \begin{tabular}{lll}
      \toprule
      LazySP & Existing & \\
      Selector & Algorithm & Result \\
      \midrule
      Expand & (Weighted) A* & Edge-equivalent \\
      & & (Theorems \ref{thm:astar-equiv-from-lazy},
                 \ref{thm:astar-equiv-to-lazy}) \\
      \addlinespace[0.3em]
      Forward & Lazy Weighted A* & Edge-equivalent \\
      & & (Theorems \ref{thm:lwastar-equiv-from-lazy},
                 \ref{thm:lwastar-equiv-to-lazy}) \\
      \addlinespace[0.3em]
      Alternate & Bidirectional Heuristic & Conjectured \\
      & Front-to-Front Algorithm & \\
      \bottomrule
   \end{tabular}%
   }%
   \caption{LazySP equivalence results.
      The A*, LWA*, and BHFFA algorithms use reopening and the dynamic
      $h_{\ms{lazy}}$ heuristic (\ref{eqn:h_lazy}).}
   \label{table:equivalences}
\end{table}

In the previous section,
we introduced LazySP as the path-selection analogue
to BFS vertex-selection algorithms.
In this section,
we make this analogy more precise.
In particular,
we show that LazySP-Expand
%(that is, LazySP with the Expand selector)
%\ajnote{name consistency}
is edge-equivalent to a variant of A*
(and Weighted A*),
and that LazySP-Forward is edge-equivalent to a variant of
Lazy Weighted A*
(see Table~\ref{table:equivalences}).
%\ajnote{Say ``as described below''?}
It is important to be specific about the conditions under which
these equivalences arise,
which we detail here.

\textbf{Edge equivalence.}
We say that two algorithms are \emph{edge-equivalent} if they
evaluate the same edges in the same order.
We consider an algorithm to have evaluated an edge
the first time the edge's true weight is requested.

\textbf{Arbitrary tiebreaking.}
For some graphs,
an algorithm may have multiple allowable choices at each iteration
(e.g. LazySP with multiple candidate shortest paths,
or A* with multiple vertices in OPEN with lowest $f$-value).
We will say that algorithm A is equivalent to algorithm B
if for any choice available to A,
there exists an allowable choice available to B
such that the same edge(s) are evaluated by each.

\textbf{A* with reopening.}
We show equivalence to variants of A* and Lazy Weighted A*
that do not use a CLOSED list to prevent
vertices from being visited more than once.
%\ssnote{Why this comparison?! Not explained.}.
%Note that if the heuristic used is $h(v) = \epsilon h_c(v)$
%with $h_c(v)$ consistent,
%a CLOSED list could potentially reduce edge evaluations
%while still guaranteeing $\epsilon$-suboptimality.

\begin{figure}
   \centering
   \begin{tikzpicture}
      \tikzset{>=latex} % arrow heads
      %\draw[step=1cm,black!10,very thin] (0,0) grid (8,4);
      \node[draw,circle,inner sep=1pt,fill=black!20] (S) at (1,1) {S};
      \node[draw,circle,inner sep=1pt] (X) at (2,2.7) {X};
      \node[draw,circle,inner sep=1pt,fill=black!20] (Y) at (3,1) {Y};
      \node[draw,circle,inner sep=1pt] (G) at (5,1) {G};
      \draw[->] (S) -- (Y) node [midway,fill=white] {1,1};
      \draw[->] (Y) -- (G) node [midway,fill=white] {1,3};
      \draw[->] (S) -- (X) node [midway,fill=white] {1,1};
      \draw[->,densely dotted] (X) -- (Y) node [midway,fill=white] {1,?};
      \node[anchor=west] at (2.3,2.9) {$h_{\ms{est}} = 2$};
      \node[anchor=west] at (2.3,2.5) {$h_{\ms{lazy}} = 4$};
      
      % for legend
      %\node at (7,2.9) {unevaluated:};
      %\draw[->,dashed] (6,2.5) -- (8,2.5)
      %   node [midway,fill=white] {($w_{est}$)\,?};
      %\node at (7,1.9) {evaluated:};
      %\draw[->] (6,1.5) -- (8,1.5)
      %   node [midway,fill=white] {($w_{est}$)\,$w$};
      \draw[->,densely dotted] (4.5,2.9) -- (6.5,2.9)
         node[midway,yshift=0.03cm,fill=white,inner sep=1pt,font=\small] {unevaled};
      \draw[->] (4.5,2.55) -- (6.5,2.55)
         node[midway,yshift=0.03cm,fill=white,inner sep=1pt,font=\small] {evaled};
      \node at (5.5,2.2) {$w_{\ms{est}},w$};
      \draw[black!10] (4.25,1.95) rectangle (6.75,3.2);
   \end{tikzpicture}
   \caption{A* comparison between
      the static goal heuristic $h_{\ms{est}}$ (\ref{eqn:h_est})
      and the dynamic goal heuristic $h_{\ms{lazy}}$ (\ref{eqn:h_lazy})
      on a simple graph from start S to goal G.
      The values of both the edge weight estimate $w_{\ms{est}}$
      and the true edge weight $w$ (for evaluated edges) are shown.
      Using either goal heuristic,
      the A* algorithm first expands vertices S and Y,
      evaluating three edges in total and leaving X and G on OPEN.
      After finding that edge YG has $w=3$,
      the dynamic heuristic value $h_{\ms{lazy}}(\mbox{X})$
      is updated from 2 to 4.
      While the A* using the static $h_{\ms{est}}$ would next expand X,
      the A* using the dynamic $h_{\ms{lazy}}$ would next expand G
      and terminate, having never evaluated edge XY.}
   \label{fig:updating-heuristic}
\end{figure}

\textbf{A* with a dynamic heuristic.}
In order to apply A* and Lazy Weighted A* to our problem,
we need a goal heuristic over vertices.
The most simple may be
\begin{equation}
   h_{\ms{est}}(v) = \min_{p : v \rightarrow v_g} \mbox{len}(p, w_{\ms{est}}).
   \label{eqn:h_est}
\end{equation}
Note that the value of this heuristic could be computed as a
pre-processing step using Dijkstra's algorithm \citep{dijkstra1959anote}
before iterations begin.
However,
in order for the equivalences to hold,
we require the use of the lazy heuristic
\begin{equation}
   h_{\ms{lazy}}(v) = \min_{p : v \rightarrow v_g} \mbox{len}(p, w_{\ms{lazy}}).
   \label{eqn:h_lazy}
\end{equation}
This heuristic is dynamic in that it depends on $w_{\ms{lazy}}$
which changes as edges are evaluated.
Therefore,
heuristic values must be recomputed for all affected vertices on OPEN
after each iteration.
%An illustrative example is shown in
%Figure~\ref{fig:updating-heuristic}.
%(We discuss efficient implementation of $h_{\ms{lazy}}$ as it relates
%to the D* family of algorithms in Section~\ref{sec:discussion}.)

\subsection{Equivalence to A*}

We show that the LazySP-Expand algorithm
is edge-equivalent to a variant of the A*
shortest-path algorithm.
%We consider the variant of A* which allows a vertex $v$ to be reopened
%if its stored cost $g[v]$ is improved.
We make use of two invariants that are maintained during the
progression of A*.
Proofs are provided in the appendix.
\begin{invariant}
If $v$ is discovered by A* and $v'$ is undiscovered,
with $v'$ a successor of $v$,
then $v$ is on OPEN.%
\label{inv:astar-cundisc-popen}%
\end{invariant}
\begin{invariant}
If $v$ and $v'$ are discovered by A*,
with $v'$ a successor of $v$,
and $g[v] + w(v,v') < g[v']$,
then $v$ is on OPEN.%
\label{inv:astar-wless-popen}%
\end{invariant}
When we say a vertex is \emph{discovered},
we mean that it is either on OPEN or CLOSED.
Note that Invariant \ref{inv:astar-wless-popen} holds
because we allow vertices to be reopened;
without reopening (and with an inconsistent heuristic),
later finding a cheaper path to $v$ (and not reopening $v'$)
would invalidate the invariant.

We will use the goal heuristic $h_{\ms{lazy}}$ from (\ref{eqn:h_lazy}).
Note that if an admissible edge weight estimator $\hat{w}$ exists
(that is, $\hat{w} \leq w$),
then our A* can approximate the Weighted A* algorithm
\citep{pohl1970weightedastar}
with parameter $\epsilon$
by using $w_{\ms{est}} = \epsilon \, \hat{w}$,
and the suboptimality bound from
Theorem~\ref{thm:lazy-optimality} holds.

\begin{figure}[t]
   \centering
   \begin{tikzpicture}
      %\draw[step=1cm,gray,very thin] (0,0) grid (8,3);
      
      \draw[fill=black!05] (2.1,1.5) ellipse (0.4cm and 0.5cm);
      \draw[fill=black!05] (5.9,1.5) ellipse (0.4cm and 0.5cm);
      \draw[fill=black!05] (4,1) ellipse (0.4cm and 0.4cm);
      
      \node[align=center] at (0.75,1.5) {$P_{\ms{candidate}}$\\(LazySP)};
      \node[align=center] at (7.25,1.5) {$S_{\ms{candidate}}$\\(A*)};
      \node[align=center] at (4,1.75) {$V_{\ms{frontier}}$};
      
      \node[fill=black,circle,inner sep=1pt] (p1) at (2.15,1.7) {};
      \node[fill=black,circle,inner sep=1pt] (p2) at (2.05,1.3) {};
      
      \node[fill=black,circle,inner sep=1pt] (s1) at (5.95,1.8) {};
      \node[fill=black,circle,inner sep=1pt] (s2) at (5.85,1.3) {};
      
      \node[fill=black,circle,inner sep=1pt] (v1) at (4.1,0.9) {};
      
      \draw[->] (p1) -- (v1);
      \draw[->] (p2) -- (v1);
      
      \draw[->] (s1) -- (v1);
      \draw[->] (s2) -- (v1);
      
   \end{tikzpicture}
   \caption{Illustration of the equivalence
      between A* and LazySP-Expand.
      After evaluating the same set of edges,
      the next edges to be evaluated by each algorithm
      can both be expressed as a surjective mapping onto
      a common set of unexpanded
      frontier vertices.
      }
   \label{fig:astar-equiv-mapping}
\end{figure}

\textbf{Equivalence.}
In order to show edge-equivalence,
we consider the case where both algorithms
are beginning a new iteration
having so far evaluated the same set of edges.

LazySP-Expand has some set $P_{\ms{candidate}}$ of allowable
candidate paths minimizing $\mbox{len}(p,w_{\ms{lazy}})$;
the Expand selector will then identify a vertex on the chosen path
for expansion.

A* will iteratively select a set of vertices from OPEN to expand.
Because it is possible that a vertex is expanded multiple times
(and only the first expansion results in edge evaluations),
we group iterations of A* into \emph{sequences},
where each sequence $s$ consists of
(a) zero or more vertices from OPEN that have already been expanded,
followed by (b) one vertex from OPEN that is to be expanded
for the first time.

We show that both the set of allowable candidate paths $P_{\ms{candidate}}$
available to LazySP-Expand
and the set of allowable candidate vertex sequences $S_{\ms{candidate}}$
available to A*
map surjectively to the same set of unexpanded frontier vertices $V_{\ms{frontier}}$
as illustrated in Figure~\ref{fig:astar-equiv-mapping}.
This is described by way of
Theorems \ref{thm:astar-equiv-from-lazy}
and \ref{thm:astar-equiv-to-lazy} below
(proofs in appendix).

\begin{theorem}
If LazySP-Expand and A* have evaluated the same set of edges,
then for any candidate path $p_{\ms{candidate}}$ chosen by LazySP
yielding frontier vertex $v_{\ms{frontier}}$,
there exists an allowable A* sequence $s_{\ms{candidate}}$
which also yields $v_{\ms{frontier}}$.
\label{thm:astar-equiv-from-lazy}
\end{theorem}

\begin{theorem}
If LazySP-Expand and A* have evaluated the same set of edges,
then for any candidate sequence $s_{\ms{candidate}}$ chosen by A*
yielding frontier vertex $v_{\ms{frontier}}$,
there exists an allowable LazySP path $p_{\ms{candidate}}$
which also yields $v_{\ms{frontier}}$.
\label{thm:astar-equiv-to-lazy}
\end{theorem}

\subsection{Equivalence to Lazy Weighted A*}

%\begin{algorithm}
%   \caption{Forward Edge Evaluation Selector}
%   \begin{algorithmic}[1]
%   \Function {\textsc{SelectForward}}{$G, p_{\ms{candidate}}$}
%   \State $e_{\ms{first}} \leftarrow$ first unevaluated $e \in p_{\ms{candidate}}$
%   \State \Return $\{ e_{\ms{first}} \}$
%   \EndFunction
%   \end{algorithmic}
%   \label{alg:selectforward}
%\end{algorithm}

In a conventional vertex expansion algorithm,
determining a successor's cost is a function of both
the cost of the edge and the value of the heuristic.
If either of these components is expensive to evaluate,
an algorithm can defer its computation by maintaining the successor
on the frontier with an approximate cost until it is expanded.
The Fast Downward algorithm \citep{helmert2006fastdownward} is motivated
by expensive heuristic evaluations in planning,
whereas the Lazy Weighted A* (LWA*) algorithm \citep{cohen2014narms}
is motivated by expensive edge evaluations in robotics.

We show that the LazySP-Forward algorithm
is edge-equivalent to a variant of the Lazy Weighted A*
shortest-path algorithm.
For a given candidate path,
the Forward selector returns the first unevaluated edge.

\textbf{Variant of Lazy Weighted A*.}
We reproduce a variant of LWA* without a CLOSED list
in Algorithm~\ref{alg:lwastar}.
For the purposes of our analysis,
the reproduction differs from the original presentation,
and we detail those differences here.
With the exception of the lack of CLOSED,
the differences do not affect the behavior of the algorithm.

\begin{algorithm}[t]
\caption{Lazy Weighted A* (without CLOSED list)}
\label{alg:lwastar}
\begin{algorithmic}[1]
\Function {\textsc{LazyWeightedA*}}{$G, w, \hat{w}, h$}
\State $g[v_{\ms{start}}] \leftarrow 0$
\State $Q_v \leftarrow \{ v_{\ms{start}} \}$
   \Comment Key: $g[v] + h(v)$
   \label{line:lwastar-key-qvertices}
\State $Q_e \leftarrow \emptyset$
   \Comment Key: $g[v] + \hat{w}(v,v') + h(v')$
   \label{line:lwastar-key-qedges}
\While {$\min(Q_v.{\mbox{TopKey}}, Q_e.{\mbox{TopKey}}) < g[v_{\ms{goal}}]$}
   \If {$Q_v.{\mbox{TopKey}} \leq Q_e.{\mbox{TopKey}}$}
      \State $v \leftarrow Q_v.{\mbox{Pop}}()$
      \For {$v' \in G.\mbox{GetSuccessors}(v)$}
         \State $Q_e.\mbox{Insert}((v,v'))$
      \EndFor
   \Else
      \State $(v,v') \leftarrow Q_e.{\mbox{Pop}}()$
      \If {$g[v'] \leq g[v] + \hat{w}(v,v')$}
         \label{line:lwastar-test}
         \State {\bf continue}
      \EndIf
      \State $g_{\ms{new}} \leftarrow g[v] + w(v,v')$
         \Comment evaluate
      \If {$g_{\ms{new}} < g[v']$}
         \State $g[v'] = g_{\ms{new}}$
         \State $Q_v.\mbox{Insert}(v')$
      \EndIf
   \EndIf
\EndWhile
\EndFunction
\end{algorithmic}
\end{algorithm}

The most obvious difference is that we present the original OPEN list
as separate vertex ($Q_v$) and edge ($Q_e$) priority queues,
with sorting keys shown on lines \ref{line:lwastar-key-qvertices}
and \ref{line:lwastar-key-qedges}.
A vertex $v$ in the original OPEN with $trueCost(v) = true$
corresponds to a vertex $v$ in $Q_v$,
whereas a vertex $v'$ in the original OPEN
with $trueCost(v') = false$ (and parent $v$)
corresponds to an edge $(v,v')$ in $Q_e$.
Use of the edge queue obviates the need for
duplicate vertices on OPEN with different parents
and the $conf(v)$ test for identifying such duplicates.
This presentation also highlights the similarity between LWA*
and the inner loop of the Batch Informed Trees (BIT*) algorithm
\citep{gammell2015bitstar}.

The second difference is that the edge usefulness test
(line 12 of the original algorithm)
has been moved from before inserting into OPEN
to after being popped from OPEN,
but before being evaluated
(line~\ref{line:lwastar-test} of Algorithm~\ref{alg:lwastar}).
This change is partially in compensation for removing the CLOSED
list.
This adjustment
does not affect the edges evaluated.

We make use of an invariant that is maintained during the
progression of Lazy Weighted A* (proof in appendix).
\begin{invariant}
For all vertex pairs $v$ and $v'$,
with $v'$ a successor of $v$,
if $g[v] + \max(w(v,v'), \hat{w}(v,v')) < g[v']$,
then either vertex $v$ is on $Q_{v}$
or edge $(v,v')$ is on $Q_e$.%
\label{inv:lwastar}%
\end{invariant}
We will use $h(v) = h_{\ms{lazy}}(v)$ from (\ref{eqn:h_lazy})
and $\hat{w} = w_{\ms{lazy}}$.
Note that the use of these dynamic heuristics requires that the
$Q_v$ and $Q_e$ be resorted after every edge is evaluated.

\textbf{Equivalence.}
The equivalence follows similarly to that for A* above.
Given the same set of edges evaluated,
the set of allowable next evaluations is identical for each
algorithm.

\begin{theorem}
If LazySP-Forward and LWA* have evaluated the same set of edges,
then for any allowable candidate path $p_{\ms{candidate}}$
chosen by LazySP yielding first unevaluated edge $e_{ab}$,
there exists an allowable LWA* sequence $s_{\ms{candidate}}$
which also yields $e_{ab}$.
\label{thm:lwastar-equiv-from-lazy}
\end{theorem}

\begin{theorem}
If LazySP-Forward and LWA* have evaluated the same set of edges,
then for any allowable sequence of vertices and edges $s_{\ms{candidate}}$
considered by LWA* yielding evaluated edge $e_{ab}$,
there exists an allowable LazySP candidate path $p_{\ms{candidate}}$
which also yields $e_{ab}$.
\label{thm:lwastar-equiv-to-lazy}
\end{theorem}

\subsection{Relation to Bidirectional Heuristic Search}

LazySP-Alternate chooses unevaluated edges from either
the beginning or the end of the candidate path at each iteration.
We conjecture that an alternating version of the Expand selector
is edge-equivalent to the
Bidirectional Heuristic Front-to-Front Algorithm
\citep{sint1977bhffa}
for appropriate lazy vertex pair heuristic,
and that LazySP-Alternate is edge-equivalent
to a bidirectional LWA*.

\begin{algorithm}[t]
   \caption{Maximum Edge Probability Selector
      \emph{(for WeightSamp and Partition path distributions)}}
   \begin{algorithmic}[1]
   \Function {\textsc{SelectMaxEdgeProb}}{$G, p_{\ms{candidate}}, \mathcal{D}_p$}
   \State $p(e) \leftarrow \Pr( \, e \in P \, )
      \mbox{ for } P \sim \mathcal{D}_p$
   \State $e_{\ms{max}} \leftarrow$ unevaluated $e \in p_{\ms{candidate}}$
      maximizing $p(e)$
   \State \Return $\{ e_{\ms{max}} \}$
   \EndFunction
   \end{algorithmic}
   \label{alg:selectmaxscore}
\end{algorithm}

\section{Novel Edge Selectors}

Because we are conducting a search over paths,
we are free to implement selectors which are not constrained to
evaluate edges in any particular order
(i.e. to maintain evaluated trees rooted at the start and goal
vertices).
In this section,
we describe a novel class of edge selectors which is designed
to reduce the total number of edges evaluated during the course
of the LazySP algorithm.
These selectors operate by maintaining a distribution over potential
paths at each iteration of the algorithm
(see Figure~\ref{fig:maxprob-selectors-overview}).
This path distribution induces a Bernoulli distribution for each
edge $e$ which indicates its probability $p(e)$ to lie on
the potential path;
at each iteration,
the selectors then choose the unevaluated edge that maximizes
this edge indicator probability (Algorithm~\ref{alg:selectmaxscore}).
The two selectors described in this section differ
with respect to how they maintain this distribution over potential paths.

% make -f e8_experiments/scripts/Makefile.lazysp-fig-dists
\begin{figure}[t]
   \centering
   \begin{tikzpicture}
      \tikzset{>=latex}
      
      \node[draw,minimum width=2.4cm,minimum height=3.0cm] (startbox) at (-3.0,0) {};
      \node[inner sep=0pt] at (-3.0,-0.35) {\includegraphics[scale=2.0]{build/lazysp-fig-dists/fig-sofar}};
      \node[align=center,font=\small,below] at (startbox.north) {known\\edges};
      
      \node[draw] (quesbox) at (-1.2,0) {?};
      
      \node[draw,minimum width=2.1cm,minimum height=3.0cm] (pathsbox) at (0.4,0) {};
      \node[inner sep=0pt] at (-0.05, 0.1) {\includegraphics[scale=0.8]{build/lazysp-fig-dists/fig-path-00}};
      \node[inner sep=0pt] at ( 0.85, 0.1) {\includegraphics[scale=0.8]{build/lazysp-fig-dists/fig-path-01}};
      \node[inner sep=0pt] at (-0.05,-0.8) {\includegraphics[scale=0.8]{build/lazysp-fig-dists/fig-path-02}};
      \node[inner sep=0pt] at ( 0.85,-0.8) {\includegraphics[scale=0.8]{build/lazysp-fig-dists/fig-path-03}};
      \node[align=center,font=\small,below] at (pathsbox.north) {path\\distribution};
      \node[align=center,font=\normalsize,above] at (pathsbox.south) {$\dots$};
      
      \node[draw,minimum width=2.4cm,minimum height=3.0cm] (goalbox) at (3.0,0) {};
      \node[inner sep=0pt] at (3.0,-0.35) {\includegraphics[scale=2.0]{build/lazysp-fig-dists/fig-dist-probs}};
      \node[align=center,font=\small,below] at (goalbox.north) {edge indicator\\distributions};
      
      \draw[->] (startbox) -- (quesbox);
      \draw[->] (quesbox) -- (pathsbox);
      \draw[->] (pathsbox) -- (goalbox);
      
   \end{tikzpicture}
   \caption{Illustration of maximum edge probability selectors.
      A distribution over paths
      (usually conditioned on the known edge evaluations)
      induces on each edge $e$ a Bernoulli distribution
      with parameter $p(e)$
      giving the probablility that it belongs to the path.
      The selector chooses the edge with the largest such probability.}
   \label{fig:maxprob-selectors-overview}
\end{figure}

\subsection{Weight Function Sampling Selector}

The first selector, WeightSamp,
is motivated by the intuition that it is preferable to evaluate edges
that are most likely to lie on the true shortest path.
Therefore,
it computes its path distribution $\mathcal{D}_p$
by performing shortest path queries
on sampled edge weight functions drawn from a distribution
$\mathcal{D}_w$.
This edge weight distribution is conditioned on the the known weights
of all previously evaluated edges $E_{\ms{eval}}$:
\begin{equation}
   \mathcal{D}_p : \mbox{SP}(w)
   \mbox{ for } w \sim \mathcal{D}_w(E_{\ms{eval}})
   \label{eqn:weightsamp}.
\end{equation}

For example,
the distribution $\mathcal{D}_w$ might consist of
the edge weights induced by a model of the distribution of
environment obstacles
(Figure~\ref{fig:weightsamp}).
Since this obstacle distribution is conditioned on the results
of known edge evaluations,
we consider the subset of worlds which are consistent
with the edges we have evaluated so far.
However,
depending on the fidelity of this model,
solving the corresponding shortest path problem for a given
sampled obstacle arrangement might require as much computation as
solving the original problem,
since it requires computing the resulting edge weights.
In practice,
we can approximate $\mathcal{D}_w$
by assuming that each edge is independently distributed.

\begin{figure}[t]
   \centering
   \begin{tikzpicture}
      \tikzset{>=latex}
      
      \node[draw,minimum width=1.8cm,minimum height=2.6cm] (startbox) at (-4.4,0) {};
      \node[inner sep=0pt] at (-4.4,-0.35) {\includegraphics[scale=1.5]{build/lazysp-fig-dists/fig-sofar}};
      \node[align=center,font=\small,below] at (startbox.north) {known\\edges};
      
      \node[draw,minimum width=1.8cm,minimum height=6cm] (abox) at (-2.2,0) {};
      \node[inner sep=0pt] at (-2.2, 1.3) {\includegraphics[scale=1.5]{build/lazysp-fig-dists/fig-world-00}};
      \node[inner sep=0pt] at (-2.2,-0.3) {\includegraphics[scale=1.5]{build/lazysp-fig-dists/fig-world-01}};
      \node[inner sep=0pt] at (-2.2,-1.9) {\includegraphics[scale=1.5]{build/lazysp-fig-dists/fig-world-02}};
      \node[align=center,font=\small,below] at (abox.north) {obstacle\\distribution};
      \node[align=center,font=\normalsize,above] at (abox.south) {$\dots$};
      
      \node[draw,minimum width=1.8cm,minimum height=6cm] (bbox) at (0,0) {};
      \node[inner sep=0pt] at (0, 1.3) {\includegraphics[scale=1.5]{build/lazysp-fig-dists/fig-wfn-00}};
      \node[inner sep=0pt] at (0,-0.3) {\includegraphics[scale=1.5]{build/lazysp-fig-dists/fig-wfn-01}};
      \node[inner sep=0pt] at (0,-1.9) {\includegraphics[scale=1.5]{build/lazysp-fig-dists/fig-wfn-02}};
      \node[align=center,font=\small,below] at (bbox.north) {weight fn\\distribution};
      \node[align=center,font=\normalsize,above] at (bbox.south) {$\dots$};
      
      \node[draw,minimum width=1.8cm,minimum height=6cm] (cbox) at (2.2,0) {};
      \node[inner sep=0pt] at (2.2, 1.3) {\includegraphics[scale=1.5]{build/lazysp-fig-dists/fig-path-00}};
      \node[inner sep=0pt] at (2.2,-0.3) {\includegraphics[scale=1.5]{build/lazysp-fig-dists/fig-path-01}};
      \node[inner sep=0pt] at (2.2,-1.9) {\includegraphics[scale=1.5]{build/lazysp-fig-dists/fig-path-02}};
      \node[align=center,font=\small,below] at (cbox.north) {path\\distribution};
      \node[align=center,font=\normalsize,above] at (cbox.south) {$\dots$};
      
      \draw[->] (startbox) -- (abox);
      \draw[->] (abox) -- (bbox);
      \draw[->] (bbox) -- (cbox);
   \end{tikzpicture}
   \caption{The WeightSamp selector uses the path distribution induced by
      solving the shortest path problem on a distribution over possible
      edge weight functions $\mathcal{D}_w$.
      In this example, samples from $\mathcal{D}_w$ are computed by
      drawing samples from $\mathcal{D}_O$,
      the distribution of obstacles that are consistent with
      the known edge evaluations.}
   \label{fig:weightsamp}
\end{figure}

\subsection{Partition Function Selector}

While the WeightSamp selector captures the intuition that it is
preferrable to focus edge evaluations in areas that are useful for
many potential paths,
the computational cost required to calculate it at each iteraction
may render it intractable.
One candidate path distribution that is more efficient to compute
follows an exponential form:
\begin{equation}
   \mathcal{D}_p : f_P(p) \propto
   \exp( - \beta \, \mbox{len}(p, w_{\ms{lazy}}) ).
\end{equation}
In other words,
we consider all potential paths $P$
between the start and goal vertices,
with shorter paths assigned more probability than longer ones
(with positive parameter $\beta$).
We call this the Partition selector
because this distribution is closely related to calculating
partition functions from statistical mechanics.
The corresponding partition function is:
\begin{equation}
   Z(P) = \sum_{p \in P}
      \exp( - \beta \, \mbox{len}(p, w_{\ms{lazy}}) ).
   \label{eqn:partitionfn}
\end{equation}
Note that the edge indicator probability
required in Algorithm~\ref{alg:selectmaxscore}
can then be written:
\begin{equation}
   p(e) = 1 - \frac{Z(P \setminus e)}{Z(P)}.
   \label{eqn:edge-ind-prob}
\end{equation}
Here, $P \setminus e$ denotes paths in $P$ that do not
contain edge $e$.

\begin{figure}
   \centering
   \subfloat[Initial $p(e)$ scores on a constant-weight
         grid with $\beta$: 50, 33, 28]{%
      \centering
      \includegraphics{build/lazysp-selscores/empty-50}
      \includegraphics{build/lazysp-selscores/empty-33}
      \includegraphics{build/lazysp-selscores/empty-28}
      \label{subfig:partition-empty}
   }
   
   \subfloat[Initial $p(e)$ scores with $\infty$-weight
         obstacles with $\beta$: 50, 33, 28]{%
      \centering
      \includegraphics{build/lazysp-selscores/gap-50}
      \includegraphics{build/lazysp-selscores/gap-33}
      \includegraphics{build/lazysp-selscores/gap-28}
      \label{subfig:partition-passage}
   }
   
   % $ rosrun e8_experiments lazysp-partall-figure.py
   % --probdir=prob-box2d08-halton-roots12
   % --snapshot-afteredges=0 --out-tikz=partall-figure-0.tex
   \subfloat[Initial $p(e)$ scores]{%
      \centering
      \includegraphics{build/lazysp-partall/partall-figure-0}
      \label{subfig:partition-example-initial}
   }
   % $ rosrun e8_experiments lazysp-partall-figure.py
   % --probdir=prob-box2d08-halton-roots12
   % --snapshot-afteredges=5 --out-tikz=partall-figure-5.tex
   \subfloat[Scores after five evaluations]{%
      \centering
      \includegraphics{build/lazysp-partall/partall-figure-5}
      \label{subfig:partition-example-after5}
   }

   \caption{Examples of the Partition selector's
      $p(e)$ edge score function.
      %(\subref{subfig:partition-empty})
      With no known obstacles,
      a high $\beta$ assigns near-unity score to only edges on the
      shortest path;
      as $\beta$ decreases and more paths are considered,
      edges immediately adjacent to the roots score highest.
      %(\subref{subfig:partition-passage})
      Since all paths must pass
      through the narrow passage,
      edges within score highly.
      %(\subref{subfig:partition-example-initial})
      For a problem with two a-priori known obstacles (dark gray),
      the score first prioritizes evaluations between the two.
      %(\subref{subfig:partition-example-after5})
      Upon finding these edges are blocked,
      the next edges that are prioritized lie along the top of the world.}
   \label{ref:example-scores}
\end{figure}

It may appear advantageous to restrict $P$ to only
\emph{simple} paths,
since all optimal paths are simple.
Unfortunately,
an algorithm for computing (\ref{eqn:edge-ind-prob}) efficiently is not
currently known in this case.
However,
in the case that $P$ consists of all paths,
there exists an efficient incremental calculation of
(\ref{eqn:partitionfn}) via a recursive formulation
which we detail here.

We use the notation $Z_{xy} = Z(P_{xy})$,
with $P_{xy}$ the set of paths from $x$ to $y$.
Suppose the values $Z_{xy}$ are known between
all pairs of vertices $x, y$ for a graph $G$.
(For a graph with no edges,
$Z_{xy}$ is 1 if $x = y$ and 0 otherwise.)
Consider a modified graph $G'$ with one additional edge $e_{ab}$
with weight $w_{ab}$.
All additional paths use the new edge $e_{ab}$ a non-zero
number of times;
the value $Z'_{xy}$ can be shown to be
\begin{equation}
   Z'_{xy} = Z_{xy} + \frac{Z_{xa} Z_{by}}{\exp(\beta w_{ab}) - Z_{ba}}
   \mbox{ if }
   \exp(\beta w_{ab}) > Z_{ba}.
\end{equation}
This form is derived from simplifying the induced geometric series;
note that if $\exp(\beta w_{ab})  \leq Z_{ba}$,
the value $Z'_{xy}$ is infinite.
One can also derive the inverse:
given values $Z'$,
calculate the values $Z$ if an edge were removed.

This incremental formulation of (\ref{eqn:partitionfn})
allows for the corresponding score $p(e)$ for edges
to be updated efficiently during each iteration of LazySP as
the $w_{\ms{lazy}}$ value for edges chosen for evaluation are updated.
In fact,
if the values $Z$ are stored in a square matrix,
the update for all pairs after an edge weight change consists of a single
vector outer product.

\section{Experiments}

We compared the seven edge selectors on three classes of shortest path
problems.
The average number of edges evaluated by each,
as well as timing results from our implementations,
are shown in Figure~\ref{fig:results}.
In each case,
the estimate was chosen so that $w_{\ms{est}} \leq w$,
so that all runs produced optimal paths.
The experimental results serve primarily to illustrate that
the A* and LWA* algorithms
(i.e. Expand and Forward)
are not optimially edge-efficient,
but they also expose differences in behavior and prompt
future research directions.
All experiments were conducted using an open-source
implementation.\footnote{%
%https://github.com/personalrobotics/multiset-planning
Link to implementation hidden for double-blind review.
}
Motion planning results were implemented using
OMPL \citep{sucan2012ompl}.

\textbf{Random partially-connected graphs.}
We tested on a set of 1000 randomly-generated undirected graphs
with $|V|=100$,
with each pair of vertices sharing an edge with probability 0.05.
Edges have an independent 0.5 probability of having infinite weight,
else the weight is uniformly distributed on $[1,2]$;
the estimated weight was unity for all edges.
For the WeightSamp selector,
we drew 1000 $w$ samples.
For the Partition selector, we used $\beta = 2$.

\textbf{Roadmap graphs on the unit square.}
We considered roadmap graphs formed via the first 100 points
of the $(2,3)$-Halton sequence on the unit square
with a connection radius of 0.15,
with 30 pairs of start and goal vertices chosen randomly.
The edge weight function was derived from 30 sampled obstacle fields
consisting of 10 randomly placed boxes
with dimensions uniform on $[0.1,0.3]$,
with each edge having infinite weight on collision,
and weight equal to its Euclidean length otherwise.
One of the resulting 900 example problems is shown in
Figure~\ref{fig:snapshots}.
For the WeightSamp selector,
we drew 1000 $w$ samples
with a na\"{\i}ve edge weight distribution in which
each edge had an independent 0.1 collision probability.
For the Partition selector, we used $\beta = 21$.

\textbf{Roadmap graphs for robot arm motion planning.}
We considered roadmap graphs in the configuration space
corresponding to 7-DOF right arm of the HERB home robot across three
motion planning problems inspired by a table clearing scenario
(see Figure~\ref{fig:herbbin0}).
The problems consisted of first moving from the robot's
home configuration to one of 7 feasible grasp configurations for a mug
(pictured),
second transferring the mug to one of 72 feasible configurations with
the mug above the blue bin,
and third returning to the home configuration.
Each problem was solved independently.
This common scenario spans various numbers of starts/goals
and allows a comparison w.r.t. difficulty at different problem
stages as discussed later.

For each problem,
50 random graphs were constructed by applying a random offset to
the 7D Halton sequence with $N = 1000$,
with additional vertices for each problem start and goal configuration.
We used an edge connection radius of 3 rad,
resulting $|E|$ ranging from 23404 to 28109.
Each edge took infinite weight on collision,
and weight equal to its Euclidean length otherwise.
For the WeightSamp selector,
we drew 1000 $w$ samples
with a na\"{\i}ve edge weight distribution in which
each edge had an independent 0.1 probability of collision.
For the Partition selector, we used $\beta = 3$.

\begin{figure*}
\centering
%\includegraphics[width=3cm]{figs/herbbin0.png}
\includegraphics[width=3.1cm]{figs/lazysp-herbarm/herbarm-roadmap.png}
\includegraphics[width=3.1cm]{figs/lazysp-herbarm/herbarm-path02.png}
%\includegraphics[width=3cm]{figs/lazysp-herbarm/herbarm-path11.png}
%\includegraphics[width=3cm]{figs/lazysp-herbarm/herbarm-path21.png}
\includegraphics[width=3.1cm]{figs/lazysp-herbarm/herbarm-path33.png}
\includegraphics[width=3.1cm]{figs/lazysp-herbarm/herbarm-path42.png}
\includegraphics[width=3.1cm]{figs/lazysp-herbarm/herbarm-path46.png}
\caption{Visualization of the first of three articulated motion
   planning problems in which the HERB robot must move its right arm
   from the start configuration (pictured)
   to any of seven grasp configurations for a mug.
   Shown is the progression of the Alternate selector on one of the
   randomly generated roadmaps;
   approximately 2\% of the 7D roadmap is shown in gray by projecting
   onto the space of end-effector positions.}
\label{fig:herbbin0}
\end{figure*}

\begin{figure}[t!]
   \centering
   \subfloat[
      Average number of edges evaluated for each problem class
         and selector.
         The minimum selector,
         along with any selector within one unit of its standard error,
         is shown in bold.
         The ArmPlan class is split into its three constituent problems.
         Online timing results are also shown,
         including the components from the invoking the selector
         and evaluating edges.
         \dag PartConn and UnitSquare involve trivial edge evaluation
         time.
         \ddag Timing for the Partition selector does not include
         pre-computation time.
         See Figure~\ref{fig:table-timing-results} for details.]
   {%
      \centering
      {\small%
      \setlength{\tabcolsep}{0.06cm}%
      \begin{tabular}{lrrrrrrr}
         \toprule
            & E\;\;\;\;
            & F\;\;\;\; & R\;\;\;\; & A\;\;\;\;
            & B\;\;\;\; & W\;\;\;\; & P\ddag\;\; \\
         \midrule
         \addlinespace[0.3em]
         PartConn &  87.10 & 35.86 & 34.84 & 22.23 & 44.81 & \textbf{20.66} & \textbf{20.39} \\
         \;\;\emph{online\dag (ms)} & \bf\emph{1.22} & \emph{1.96} & \emph{1.86} & \bf\emph{1.20} & \emph{2.41} & \emph{4807.19} & \emph{3.32} \\
         \;\;\;\;\emph{sel (ms)} & \emph{0.02} & \emph{0.01} & \emph{0.01} & \emph{0.01} & \emph{0.03} & \emph{4805.64} & \emph{2.07} \\
         \addlinespace[0.3em]
         UnitSquare &  69.21 & 27.29 & 27.69 & 17.82 & 32.62 & 15.58 & \textbf{14.08} \\
         \;\;\emph{online\dag (ms)} & \bf\emph{0.91} & \emph{1.47} & \emph{1.49} & \bf\emph{0.94} & \emph{1.71} & \emph{3864.95} & \emph{1.72} \\
         \;\;\;\;\emph{sel (ms)} & \emph{0.01} & \emph{0.01} & \emph{0.01} & \emph{0.01} & \emph{0.02} & \emph{3863.49} & \emph{0.87} \\
         \addlinespace[0.3em]
         ArmPlan(avg) & 949.05 & 63.62 & 74.94 & 55.48 & 68.01 & 56.93 & \textbf{48.07} \\
         \;\;\emph{online (s)} & \emph{269.82} & \bf\emph{5.90} & \emph{8.22} & \bf\emph{5.96} & \emph{7.34} & \emph{3402.21} & \bf\emph{5.80} \\
         \;\;\;\;\emph{sel (s)} & \emph{0.00} & \emph{0.00} & \emph{0.00} & \emph{0.00} & \emph{0.00} & \emph{3392.76} & \emph{1.54} \\
         \;\;\;\;\emph{eval (s)} & \emph{269.78} & \emph{5.87} & \emph{8.20} & \emph{5.94} & \emph{7.31} & \emph{9.39} & \emph{4.21} \\
         \addlinespace[0.3em]
         ArmPlan1 &  344.74 & \textbf{49.72} & 95.58 & 59.44 & 58.90 & 73.72 & \textbf{50.66} \\
         \;\;\emph{online (s)} & \emph{109.09} & \bf\emph{4.81} & \emph{14.81} & \emph{7.03} & \emph{7.91} & \emph{3375.35} & \emph{7.25} \\
         \;\;\;\;\emph{sel (s)} & \emph{0.00} & \emph{0.00} & \emph{0.00} & \emph{0.00} & \emph{0.00} & \emph{3358.82} & \emph{1.61} \\
         \;\;\;\;\emph{eval (s)} & \emph{109.07} & \emph{4.78} & \emph{14.77} & \emph{7.01} & \emph{7.88} & \emph{16.47} & \emph{5.59} \\
         \addlinespace[0.3em]
         ArmPlan2 &  657.02 & \textbf{62.24} & 98.54 & 69.96 & 75.88 & \textbf{66.24} & \textbf{62.16} \\
         \;\;\emph{online (s)} & \emph{166.19} & \bf\emph{3.27} & \emph{7.36} & \emph{5.95} & \emph{5.63} & \emph{4758.04} & \emph{5.99} \\
         \;\;\;\;\emph{sel (s)} & \emph{0.00} & \emph{0.00} & \emph{0.00} & \emph{0.00} & \emph{0.00} & \emph{4750.16} & \emph{2.03} \\
         \;\;\;\;\emph{eval (s)} & \emph{166.17} & \emph{3.26} & \emph{7.34} & \emph{5.93} & \emph{5.61} & \emph{7.82} & \emph{3.91} \\
         \addlinespace[0.3em]
         ArmPlan3 & 1845.38 & 78.90 & \textbf{30.70} & 37.04 & 69.26 & \textbf{30.82} & \textbf{31.38} \\
         \;\;\emph{online (s)} & \emph{534.16} & \emph{9.61} & \bf\emph{2.50} & \emph{4.91} & \emph{8.47} & \emph{2073.23} & \emph{4.17} \\
         \;\;\;\;\emph{sel (s)} & \emph{0.00} & \emph{0.00} & \emph{0.00} & \emph{0.00} & \emph{0.00} & \emph{2069.29} & \emph{0.98} \\
         \;\;\;\;\emph{eval (s)} & \emph{534.10} & \emph{9.58} & \emph{2.48} & \emph{4.89} & \emph{8.44} & \emph{3.90} & \emph{3.15} \\
         \addlinespace[0.15em]
         \bottomrule
      \end{tabular}%
      }%
      \label{subfig:table-results}
   }
   
   \vspace{0.1in}
   
   \subfloat[PartConn]{%
      \centering
      \begin{tikzpicture}
      \begin{axis}[
         width=4.1cm,
         height=4.0cm,
         ybar,
         bar width=7,
         ymin=0,ymax=90,
         ytick pos=bottom,
         symbolic x coords={E, F, R, A, B, W, P},
         xtick=data,
         xtick pos=left,
         ymajorgrids,
         ymajorticks=false,
         ticklabel style={font=\small}
         ]
      \node[circle,fill=white,inner sep=1pt,text=black!40] at (axis cs:P,40) {\scriptsize 40};
      \node[circle,fill=white,inner sep=1pt,text=black!40] at (axis cs:P,60) {\scriptsize 60};
      \node[circle,fill=white,inner sep=1pt,text=black!40] at (axis cs:P,80) {\scriptsize 80};
      \addplot[color=black,fill=black!20,error bars/.cd,y dir=both,y explicit] coordinates {
         (E, 87.10) +- (2.39,2.39)
         (F, 35.86) +- (1.04,1.04)
         (R, 34.84) +- (1.04,1.04)
         (A, 22.23) +- (0.60,0.60)
         (B, 44.81) +- (1.11,1.11)
         (W, 20.66) +- (0.57,0.57)
         (P, 20.39) +- (0.56,0.56)
      };
      \end{axis}
      \end{tikzpicture}
   }
   \subfloat[UnitSquare]{%
      \centering
      \begin{tikzpicture}
      \begin{axis}[
         width=4.1cm,
         height=4.0cm,
         ybar,
         bar width=7,
         ymin=0,ymax=90,
         ytick pos=bottom,
         symbolic x coords={E, F, R, A, B, W, P},
         xtick=data,
         xtick pos=left,
         ymajorgrids,
         ymajorticks=false,
         ticklabel style={font=\small}
         ]
      \node[circle,fill=white,inner sep=1pt,text=black!40] at (axis cs:P,40) {\scriptsize 40};
      \node[circle,fill=white,inner sep=1pt,text=black!40] at (axis cs:P,60) {\scriptsize 60};
      \node[circle,fill=white,inner sep=1pt,text=black!40] at (axis cs:P,80) {\scriptsize 80};
      \addplot[color=black,fill=black!20,error bars/.cd,y dir=both,y explicit] coordinates {
         (E, 69.21) +- (2.55,2.55)
         (F, 27.29) +- (1.03,1.03)
         (R, 27.69) +- (1.02,1.02)
         (A, 17.82) +- (0.60,0.60)
         (B, 32.62) +- (0.72,0.72)
         (W, 15.58) +- (0.47,0.47)
         (P, 14.08) +- (0.46,0.46)
      };
      \end{axis}
      \end{tikzpicture}
   }
   \subfloat[ArmPlan]{%
      \centering
      \begin{tikzpicture}
      \begin{axis}[
         width=4.1cm,
         height=4.0cm,
         ybar,
         bar width=7,
         ymin=0,ymax=115,
         max space between ticks=10,
         ytick pos=bottom,
         symbolic x coords={E, F, R, A, B, W, P},
         xtick=data,
         xtick pos=left,
         ymajorgrids,
         ymajorticks=false,
         ticklabel style={font=\small}
         ]
      \node[circle,fill=white,inner sep=0pt,text=black!40] at (axis cs:P,60) {\scriptsize 60};
      \node[circle,fill=white,inner sep=0pt,text=black!40] at (axis cs:P,80) {\scriptsize 80};
      \node[circle,fill=white,inner sep=0pt,text=black!40] at (axis cs:P,100) {\scriptsize 100};
      \addplot[color=black,fill=black!20,error bars/.cd,y dir=both,y explicit] coordinates {
         (E, 115) +- (0,0) % 49.06 +- 61.63.46
         (F, 63.62) +- (4.15,4.15)
         (R, 74.94) +- (5.07,5.07)
         (A, 55.48) +- (2.95,2.95)
         (B, 68.01) +- (3.86,3.86)
         (W, 56.93) +- (3.37,3.37)
         (P, 48.07) +- (2.44,2.44)
      };
      \node[align=center,anchor=north,inner sep=0pt] at (axis cs:E,111) {\scriptsize $\uparrow$};
      \end{axis}
      \end{tikzpicture}
   }
   \caption{
      Experimental results for the three problem classes
      across each of the seven selectors,
      E:Expand, F:Forward, R:Reverse,
      A:Alternate, B:Bisection,
      W:WeightSamp, and P:Partition.
      In addition to the summary table (a),
      the plots (b-d) show summary statistics for
      each problem class.
      The means and standard errors in (b-c) are across the
      1000 and 900 problem instances, respectively.
      The means and standard errors in (d) are for
      the average across the three constituent problems
      for each of the 50 sampled roadmaps.}
   \label{fig:results}
\end{figure}

\section{Discussion}
\label{sec:discussion}

The first observation that is evident from the experimental results
is that lazy evaluation
-- whether using Forward (LWA*) or one of the other selectors --
grossly outperforms Expand (A*).
The relative penalty that Expand incurs by evaluating all edges from
each expanded vertex is a function of the graph's branching factor.

Since the Forward and Reverse selectors are simply mirrors of each
other,
they exhibit similar performance
averaged across the PartConn and UnitSquare problem classes,
which are symmetric.
However,
this need not the case for a particular instance.
For example,
the start of ArmPlan1 and the goal of ArmPlan3 consist
of the arm's single home configuration in a relatively confined space.
As shown in the table in
Figure~\ref{fig:results}\subref{subfig:table-results},
it appears that the better selector on these problems attempts
to solve the more constrained side of the problem first.
While it may be difficult to determine a priori which part of the
problem will be the most constrained,
the simple Alternate selector's respectable performance
suggests that it may be a reasonable compromise.

The per-path plots at the bottom of Figure~\ref{fig:snapshots}
allow us to characterize the selectors' behavior.
For example,
Alternate often evaluates several edges on each path before finding
an obstacle.
Its early evaluations also tend to be useful later,
and it terminates after considering 10 paths on the illustrated problem.
In contast, Bisection exhibits a fail-fast strategy,
quickly invalidating most paths after a single evaluation,
but needing 16 such paths (with very little reuse)
before it terminates.
In general, the Bisection selector did not outperform any of the
lazy selectors in terms of number of edges evaluated.
However,
it may be well suited to problem domains in which
evaluations that fail tend be less costly.

The novel selectors based on path distributions tend to minimize
edge evaluations on the problems we considered.
While the WeightSamp selector performs similarly to Partition on the
simpler problems,
it performs less well in the ArmPlan domain.
This may be because many more samples are needed to appoximate
the requisite path distribution.

The path distribution selectors are motivated by focusing evaluation
effort in areas that are useful for many distinct candidate paths,
as illustrated in Figure~\ref{ref:example-scores}.
Note that in the absence of a priori knowledge,
the edges nearest to the start and goal tend to have the highest
$p(e)$ score,
since they are members of many potential paths.
Because it tends to focus evaluations in a similar way,
the Alternate selector may serve as a simple proxy for the
more complex selectors.

We note that
an optimal edge selector could be theoretically achieved by posing the
edge selection problem as a POMDP,
given a probabalistic model of the true costs.
While likely intractable in complex domains,
exploring this solution may yield useful approximations or insights.


\chapter{Incremental Bidirectional Shortest-Path Search}
\label{chap:ibid}

Solving the dynamic single-pair shortest path (SPSP) problem.
AKA two-terminal shortest-path problem.

Bidirectional approach:
Partially solve a single-source shortest-path (SSSP) problem
and the complementary single-destination shortest-path problem (SDSP).

Motivate this with LazySP.
What if your heuristic is not that great?

Combine bidirectional search,
heuristic-guided search,
and incremental search.

Solve the Bellman-Ford equations in the correct order.

This is a relatively straightforward integration of incremental search
(DynamicSWSF-FP \citep{ramalingam1996})
and bidirectional Dijkstra's search \citep{goldberg2005spexternalmemory}.
The most subtle part of the algorthm is getting the termination
condition right.
The benefit of bidirectional search for an problem that is
uninformed by a heuristic
is that it tends to explore a smaller subset of the graph
(view bubbles).
We have found that some problems with weak heuristics,
it outperforms LPA*.
See some plots below.

\begin{table}
\centering
\begin{tabular}{ccc}
   \toprule
   & Unidirectional & Bidirectional \\
   \midrule
   \addlinespace[0.2em]
   Complete
      & Dijkstra \citep{dijkstra1959anote}
      & Bidirectional Dijkstra \citep{luby1989bidijk} \\
   \addlinespace[-0.2em]
   \emph{(Heuristic)}
      & \emph{A* \citep{hart1968astar}}
      & \emph{Bidirectional A* \citep{ikeda1994betterroutes}} \\
   \addlinespace[0.3em]
   Incremental
      & DynamicSWSF-FP \citep{ramalingam1996}
      & \multirow{2}{*}{IBID}  \\
   \addlinespace[-0.2em]
   \emph{(Heuristic)}
      & \emph{Lifelong Planning A* \citep{koenig2004lpastar}}
      & \\
   \addlinespace[0.2em]
   \bottomrule
\end{tabular}
\caption{A table.}
\end{table}

We are not interested in domains that are chiefly memory-constrained,
so no need to consider iterative-deepening approaches,
including bidirectional variants as proposed by
Kaindl and Kainz, ``Bidirectional Heuristic Search Reconsidered,''
Journal of AI Research 1997.

\section{Prior Work}

The \emph{shortest path problem} on graphs has been extensively
studied over the past six decades.
Consider a directed graph $G = (V,E)$ and accompanying edge weight
function $w : E \rightarrow \mathbb{R}$,
with the length of a path equal to the sum of the weights of its
constituent edges.
I include here a brief survey of algorithmic work on the
\emph{single-pair} (a.k.a. point-to-point) problem,
where a path of minimal length is sought
between particular source and target vertices
$s,t \in V$.
I also consider only graphs without negative-length cycles.

\subsection{Pathfinding via the Source Distance Function}

The pioneering pathfinding algorithms of the late 1950s address
the \emph{single-source} problem,
where shortest paths are calculated from $s$ to all vertices on
the graph.
They proceed by calculating the \emph{distance function}
$d_s : V \rightarrow \mathbb{R}$,
which is characterized by
\begin{equation}
   d_s(s) = 0
   \quad\mbox{and}\quad
   \forall v \neq s,\;
   d_s(v) = \min_{u \in \mbox{\scriptsize Pred}(v)} d_s(u) + w(u,v).
   \label{eqn:distance-function}
\end{equation}
The distance function is akin to the \emph{value function}
in more general decision problems addressed by dynamic programming,
and (\ref{eqn:distance-function}) is the Bellman equation
\citep{bellman1958routing}.
This characterization also follows implicitly from early results for
the all-pairs problem
\citep{shimbel1955communicationnets, beckmann1955transportation}.
A shortest path to a target $t$ can be generated trivially
by walking backwards to $s$ guided by the function $d_s$.

Algorithms for computing $d_s$ rely on the concept of
\emph{relaxation}
as described by Ford \citep{ford1955networkflowtheory}.
The function $d_s$
is initialized to the upper bound $\infty$ for $v \neq s$,
and edges $(u,v)$ for which $d_s(v) > d_s(u) + w(u,v)$,
thereby violating (\ref{eqn:distance-function}),
are relaxed by updating $d_s(v)$
with the reduced value $d_s(u) + w(u,v)$.
The well-known Bellman-Ford method
\citep{shimbel1955communicationnets, bellman1958routing,
moore1959spmaze}
iterates through all edges repeatedly until convergence
(at most $|V|$ repetitions are sufficient).

Soon afterwards,
several researchers
identified \citep{leyzorek1957modeltechniques, dijkstra1959anote}
an efficient ordering of edge relaxations
if $w$ is non-negative.
Dijkstra's algorithm relaxes edges $(u,v)$
in increasing order of $d_s(u)$.
In does this by initially marking all vertices as {\sc Open},
and at each iteration moving to {\sc Closed}
the vertex $u$ minimizing $d_s$
and relaxing all outgoing edges $(u,v)$ from $u$.
It is guaranteed to consider each vertex
(and therefore relax each edge) at most once.

\subsection{Bidirectional Search}

The single-pair problem can therefore be solved
via Dijkstra's algorithm
by (partially) computing the source distance $d_s$ until it
includes the target vertex.
However,
it was conjectured that a path might be found more efficiently
by simultaneously calculating the complementary
target distance function $d_t$
until the domains of the two functions ``overlap.''
The first mention of such a bi-directional algorithm
was proposed by Dantzig \citep{dantzig1963linearprogramming},
and the first precisely described algorithm was presented by
Nicholson \citep{nicholson1966shortest}.
Implementation of a sound and efficient algorithm
turns on two important questions:
(a) how to balance the two directions of the search,
and (b) when and how to terminate with a shortest path.

A correct termination condition is surprisingly subtle,%
\marginnote{There were early incorrect attempts at a sound
termination condition
\citep{berge1965programminggamestransportation}.}
with several correct variations proposed
\citep{nicholson1966shortest, dreyfus1969appraisalsp,
pohl1969bidirectional, goldberg2005spexternalmemory}.
The difficulty stems from the fact that the first vertex to be
{\sc Closed} by the searches in both directions
need not lie on the shortest path.

The general bidirectional algorithm also leaves open the strategy
used to balance the progression of the two search directions.
Options based on alternating \citep{dantzig1963linearprogramming},
or selecting the direction with the smaller {\sc Open} distance
\citep{nicholson1966shortest}
or {\sc Open} (and finite) set cardinality
\citep{pohl1969bidirectional}
were proposed.
It was further shown that selecting only from the source direction
reproduces Dijkstra's algorithm.

\subsection{Heuristic Search}

Heuristic methods such as the Graph Traverser
\citep{doran1966graphtraverser} were originally
applied to pathfinding problems in order to find non-optimal
solutions more economically.
These unidirectional methods proceed similarly to Dijkstra's algorithm,
but instead of prioritizing {\sc Open} vertices
based on their source distance $d_s$,
they use a target-directed heuristic function $h_t$.
Hart, Nilsson, and Raphael \citep{hart1968astar} discovered that
these approaches can be combined ($d_s + h_t$) to yield
an admissible algorithm (A*) for the shortest-path problem,
as long as $h_t$ meets certain conditions.

Attempts to provide a bidirectional algorithm which incorporates
heuristics generally take one of three approaches.
\cdnote{I need to deep-dive here to write this correctly.}

First,
front-to-front methods
could evaluate the heuristic between all pairs in the two
{\sc Open} sets.
Expensive.

Second,
perform two heuristic-informed searches,
and account for the connection problem via a complex
termination condition.
Not necessarily efficient.
(Pohl cites Berge?)
Missile analogy.

Third,
waste (same heuristic function).

Concept of waste \citep{pohl1969bidirectional}.
I think this subsumes A*.

Talk about the 94 paper \citep{ikeda1994betterroutes}
expressing A* as a search on
the waste graph.

As a potential function.
Also Goldberg \citep{goldberg2005spexternalmemory}.

To integrate: \citep{dechter1984bfsastaropt}.

\subsection{Incremental Search}

This stuff is more modern (1996, 2004).

DynamicSWSF-FP \citep{ramalingam1996}.

Revisit Bellman equation.

Apply waste to incremental search to get
incremental heuristic search.

\subsection{Incremental Heuristic Search}

Lifelong Planning A* \citep{koenig2004lpastar}.

\section{Termination Conditions}

What happens upon an encounter between the forward and reverse searches?
Goldberg \citep{goldberg2005spexternalmemory}
discusses the correct termination condition for the 
Bidirectional Dijkstra algorithm.

\section{Prioritizing Directions}

So, we can conduct expansions from the queues for either direction.
How should we proceed?
We do so via what (Pohl 1971) called a ``cardinality criterion''.

\section{The Algorithm}

The main outline of IBiD is given in Algorithm~\ref{alg:ibid}.
IBiD conducts two independent DynamicSWSF-FP searches
(Algorithm~\ref{alg:ibid-two-dynamicswsffps}).

\begin{algorithm}[t]
   \caption{IBiD Outline}
   \label{alg:ibid}
   \begin{algorithmic}[1]
      \Procedure {Main} {\,}
         \State $\mbox{\sc InitializeSource}(); \; \mbox{\sc InitializeTarget}()$
         \State $Q_c \gets \emptyset$
            \Comment $\mbox{ key for } (u,v): d_s(u) + w(u,v) + d_t(v)$
         \Loop
            \While {not $\mbox{\sc TerminationCondition}()$}
               \If {$Q_s.\mbox{TopKey} < Q_t.\mbox{TopKey}$}
                     \Comment prioritize arbitrarily
                  \State $\mbox{\sc ProcessSourceQueue}(u)$
               \Else
                  \State $\mbox{\sc ProcessTargetQueue}(u)$
               \EndIf
               \State Ensure $(u,v) \in Q_c$ iff
                  $u \neq Q_s$, $v \neq Q_t$, key $\neq \infty$
            \EndWhile
            \State $(u_c,v_c) \gets Q_c.\mbox{Top}$
            \State $\pi \gets
               ( \mbox{walk } d_s \mbox{ from } u_c \mbox{ to } s )
               \cup
               ( \mbox{walk } d_t \mbox{ from } v_c \mbox{ to } t )$
            \State wait for edges $(u,v) \in E_{\ms{delta}}$ with changed weights $w(u,v)$
            \State $\mbox{\sc NotifyWeightChanges}(E_{\ms{delta}})$
         \EndLoop
      \EndProcedure
      \Function {TerminationCondition} {\,}
         \State $(u_c,v_c) \gets Q_c.\mbox{TopKey}$
            \Comment return False if $Q_c$ empty
         \If {$Q_s.\mbox{TopKey} + Q_t.\mbox{TopKey} < d_s(u_c) + w(u_c,v_c) + d_t(v_c)$}
            \State \Return False
         \EndIf
         \If {$Q_s.\mbox{TopKey} < d_s(u_c)$
               \mbox{\bf or} $Q_t.\mbox{TopKey} < d_t(v_c)$}
            \State \Return False
         \EndIf
         \State \Return True
      \EndFunction
      \Procedure {NotifyWeightChanges} {$E_{\ms{delta}}$}
         \ForAll {$(u,v) \in E_{\ms{delta}}$}
            \State $\mbox{\sc UpdateSourceDistance}(v)$
            \State $\mbox{\sc UpdateTargetDistance}(u)$
         \EndFor
         \State Ensure $(u,v) \in Q_c$ iff
            $u \neq Q_s$, $v \neq Q_t$, key $\neq \infty$
      \EndProcedure
   \end{algorithmic}
\end{algorithm}

{\floatevery{algorithm}{\setlength\hsize{16.85cm}}
\begin{algorithm}[t]
   \caption{As a bidirectional algorithm,
      IBiD conducts two independent DynamicSWSF-FP searches,
      one computing distance from the source vertex,
      and the other computing distance to the target vertex.}
   \label{alg:ibid-two-dynamicswsffps}
   \begin{minipage}[t]{8.2cm}
      \begin{algorithmic}[1]
         \Procedure {InitializeSource} {\,\!}
            \ForAll {$v \in V$}
               \State $d_s(v) \gets \infty; \;\; r_s(v) \gets \infty$
            \EndFor
            \State $r_s(s) \gets 0$
            \State $Q_s \gets \{ s \}$
               \Comment $\mbox{ key for } v: \min\big(r_s(v),d_s(v)\big)$
            \State $\mbox{\sc ProcessSourceQueue}()$
         \EndProcedure
         \Procedure {UpdateSourceDistance} {$v$}
            \If {$v \neq s$}
               \State $r_s(v) \gets \displaystyle\min_{u \in \mbox{\scriptsize Pred}(v)}
                  \big( d_s(u) + w(u,v) \big)$
            \EndIf
            \State Ensure $v \in Q_s$ iff $d_s(v) \neq r_s(v)$
         \EndProcedure
         \Procedure {ProcessSourceQueue} {\,\!}
            \State $u \gets Q_s.\mbox{Pop}$
            \If {$r_s(u) < d_s(u)$}
                  \Comment over-consistent
               \State $d_s(u) \gets r_s(u)$
               \ForAll {$v \in \mbox{Succ}(u)$}
                  \State $\mbox{\sc UpdateSourceDistance}(v)$
               \EndFor
            \Else
                  \Comment under-consistent
               \State $d_s(u) \gets \infty$
               \ForAll {$v \in \mbox{Succ}(u) \cup u$}
                  \State $\mbox{\sc UpdateSourceDistance}(v)$
               \EndFor
            \EndIf
         \EndProcedure
         \algstore{ibid-two-dynamicswsffps}
      \end{algorithmic}
   \end{minipage}
   \quad
   \begin{minipage}[t]{8.2cm}
      \begin{algorithmic}[1]
         \algrestore{ibid-two-dynamicswsffps}
         \Procedure {InitializeTarget} {\,\!}
            \ForAll {$v \in V$}
               \State $d_t(v) \gets \infty; \;\; r_t(v) \gets \infty$
            \EndFor
            \State $r_t(t) \gets 0$
            \State $Q_t \gets \{ t \}$
               \Comment $\mbox{ key for } v: \min\big(r_t(v),d_t(v)\big)$
            \State $\mbox{\sc ProcessTargetQueue}()$
         \EndProcedure
         \Procedure {UpdateTargetDistance} {$u$}
            \If {$u \neq t$}
               \State $r_t(u) \gets \displaystyle\min_{v \in \mbox{\scriptsize Succ}(u)}
                  \big( w(u,v) + d_t(v) \big)$
            \EndIf
            \State Ensure $u \in Q_t$ iff $d_t(u) \neq r_t(u)$
         \EndProcedure
         \Procedure {ProcessTargetQueue} {\,\!}
            \State $v \gets Q_t.\mbox{Pop}$
            \If {$r_t(v) < d_t(v)$}
                  \Comment over-consistent
               \State $d_t(v) \gets r_t(v)$
               \ForAll {$u \in \mbox{Pred}(v)$}
                  \State $\mbox{\sc UpdateTargetDistance}(u)$
               \EndFor
            \Else
                  \Comment under-consistent
               \State $d_t(v) \gets \infty$
               \ForAll {$u \in \mbox{Pred}(v) \cup v$}
                  \State $\mbox{\sc UpdateTargetDistance}(u)$
               \EndFor
            \EndIf
         \EndProcedure
      \end{algorithmic}
   \end{minipage}
\end{algorithm}
} % floatevery width adjustment

\section{Examples}

See Figure~\ref{fig:incbi-lpastar-fig1-heurchange}
and Figure~\ref{fig:incbi-lpastar-fig1}.

\begin{figure}
   \centering%
   
   \includegraphics{build/incbi-lpastar-fig1/lpastar-heurnone-original}%
   \;\;%
   \includegraphics{build/incbi-lpastar-fig1/incbi-heurnone-original}%
   
   \vspace{0.2cm}
   
   \includegraphics{build/incbi-lpastar-fig1/lpastar-heurhalf-original}%
   \;\;%
   \includegraphics{build/incbi-lpastar-fig1/incbi-heurhalf-original}%
   
   \vspace{0.2cm}
   
   \includegraphics{build/incbi-lpastar-fig1/lpastar-heurfull-original}%
   \;\;%
   \includegraphics{build/incbi-lpastar-fig1/incbi-heurfull-original}%
   
   \caption{Illustration of behavior of IBiD on a single
      (non-incremental) shortest path problem.
      At left, IBiD uses the unidirectional start-side expansion
      strategy.
      At right, IBiD uses the bidirectional distance-balanaced
      expansion strategy.
      Start and goal heuristic functions are available;
      the unidirectional search uses a potential function based
      on the goal heuristic,
      and the bidirectional search a potential function using
      the average heuristic.
      IBiD is run with three different potential function weights:
      0.0 (top), 0.5 (middle), and 1.0 (bottom).
      IBiD therefore preforms equivalently to
      Dijkstra's algorithm (top-left),
      Bidirectional Dijkstra's (top-right),
      A* (bottom-left),
      and Bidirectional A* (bottom-right).}
   \label{fig:incbi-lpastar-fig1-heurchange}
\end{figure}

\begin{figure}
   \centering%
   
   \includegraphics{build/incbi-lpastar-fig1/lpastar-heurfull-original}%
   \;\;%
   \includegraphics{build/incbi-lpastar-fig1/lpastar-heurfull-changed}%
   
   \vspace{0.2cm}
   
   \includegraphics{build/incbi-lpastar-fig1/incbi-heurfull-original}%
   \;\;%
   \includegraphics{build/incbi-lpastar-fig1/incbi-heurfull-changed}%
   
   \caption{IBiD with only source-side expansions and a goal-side
      heuristic (top) proceeds identically to Lifelong Planning A*,
      performing 37 expansions on the original world (left)
      followed by 18 expansions over 14 vertices on the chanced
      world (right).
      IBiD with distance-balanced expansions and an average
      potential (bottom)
      performs 30 expansions on the original world
      followed by 18 expansions over 15 vertices on the changed
      world.}
   \label{fig:incbi-lpastar-fig1}
\end{figure}

\begin{figure*}
   \centering%
   
   \begin{tabular}{ccc}
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/pgoalnone-balfwd.png}\\556,209 expansions}
      &
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/pavgnone-baldist.png}\\319,938 expansions}
      &
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/pavgnone-balcard.png}\\281,413 expansions}
      \vspace{0.3cm}
      \\
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/pgoalhalf-balfwd.png}\\297,414 expansions}
      &
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/pavghalf-baldist.png}\\206,625 expansions}
      &
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/pavghalf-balcard.png}\\178,929 expansions}
      \vspace{0.3cm}
      \\
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/pgoalfull-balfwd.png}\\82,915 expansions}
      &
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/pavgfull-baldist.png}\\95,759 expansions}
      &
      \specialcell{\includegraphics[width=5cm]{figs/incbi-road-ne/pavgfull-balcard.png}\\69,218 expansions}
      \vspace{0.5cm}
   \end{tabular}
   
   \caption{Comparison between various heuristic strengths and
      balancing strageties on a single-pair road network problem.
      A path with shortest transit time is sought.
      The heuristic strength varies from no heuristic (top)
      to a full-strength heuristic (bottom).
      At left, a foward-only balancer is used, so that the
      top-left is equivalent to Dijkstra's algorithm,
      and the bottom-left is equivalent to A*.
      The middle column uses a balanced distance strategy.
      The right column uses a balanced cardinality strategy.}
   \label{fig:incbi-road-ne}
\end{figure*}

\chapter{Maximizing Utility in Motion Planning}
\label{chap:lemur}

Here, we introduce LEMUR.


\chapter{Application: Planning Multi-Step Manipulation Tasks}
\label{chap:family}


\chapter{Conclusion}

Here is a conclusion.


\appendix

\chapter{Appendix: LazySP Proofs}
\label{sec:appendix-proofs}

\subsection{LazySP}

\begin{proof}[Proof of Theorem \ref{thm:lazy-optimality}]
Let $p^*$ be an optimal path w.r.t. $w$,
with $\ell^* = \mbox{len}(p^*, w)$.
Since $w_{\ms{est}}(e) \leq \epsilon \, w(e)$ and $\epsilon \geq 1$,
it follows that regardless of which edges are stored in $W_{\ms{eval}}$,
$w_{\ms{lazy}}(e) \leq \epsilon \, w(e)$,
and therefore
$\mbox{len}(p^*, w_{\ms{lazy}}) \leq \epsilon \, \ell^*$.
Now,
since the inner \textsc{ShortestPath} algorithm terminated with
$p_{\ms{ret}}$,
we know that
$\mbox{len}(p_{\ms{ret}}, w_{\ms{lazy}}) \leq \mbox{len}(p^*, w_{\ms{lazy}})$.
Further,
since the algorithm terminated with $p_{\ms{ret}}$,
each edge on $p_{\ms{ret}}$ has been evaluated;
therefore,
$\mbox{len}(p_{\ms{ret}}, w) = \mbox{len}(p_{\ms{ret}}, w_{\ms{lazy}})$.
Therefore,
$\mbox{len}(p_{\ms{ret}}, w) \leq \epsilon \, \ell^*$.
\end{proof}

\begin{proof}[Proof of Theorem \ref{thm:lazy-completeness}]
In this case,
the algorithm will evaluate at least unevaluated edge at
each iteration.
Since there are a finite number of edges,
eventually the algorithm will terminate.
\end{proof}

\subsection{A* Equivalence}

\begin{proof}[Proof of Invariant \ref{inv:astar-cundisc-popen}]
If $v$ is discovered, then it must either be on OPEN or CLOSED.
$v$ can be on CLOSED only after it has been expanded,
in which case $s$ would be discovered (which it is not).
Therefore, $v$ must be on OPEN.
\end{proof}

\begin{proof}[Proof of Invariant \ref{inv:astar-wless-popen}]
Clearly the invariant holds at the beginning of the algorithm,
with only $v_{\ms{start}}$ on OPEN.
If the invariant were to no longer hold after some iteration,
then there must exist some pair of discovered vertices $v$ and $v'$
with $v$ on CLOSED and $g[v] + w(v,v') < g[v']$.
Since $v$ is on CLOSED,
it must have been expanded at some previous iteration,
immediately after which the inequality could not have held
because $g[v']$ is updated upon expansion of $v$.
Therefore,
the inequality must have newly held after some intervening iteration,
with $v$ remaining on CLOSED.
Since the values $g$ are monotonically non-increasing and $w$ is fixed,
this implies that $g[v]$ must have been updated (lower).
However,
if this had happened,
then $v$ would have been removed from CLOSED and placed on OPEN.
This contradiction implies that the invariant holds at every iteration.
\end{proof}

\begin{proof}[Proof of Theorem \ref{thm:astar-equiv-from-lazy}]
Consider path $p^*_{\ms{lazy}}$ with length $\ell^*_{\ms{lazy}}$
yielding frontier vertex $v_{\ms{frontier}}$ via \textsc{SelectExpand}.
Construct a vertex sequence $s$ as follows.
Initialize $s$ with the vertices on $p^*_{\ms{lazy}}$
from $v_{\ms{start}}$ to $v_{\ms{frontier}}$, inclusive.
Let $N$ be the number of consecutive vertices at the start of $s$
for which $f(v) = \ell^*_{\ms{lazy}}$
(Note that the first vertex on $p^*_{\ms{lazy}}$, $v_{\ms{start}}$,
must have $f(v_{\ms{start}}) = \ell^*_{\ms{lazy}}$,
so $N \geq 1$.)
Remove from the start of $s$ the first $N-1$ vertices.
Note that at most the first vertex on $s$ has
$f(v) = \ell^*_{\ms{lazy}}$,
and the last vertex on $s$ must be $v_{\ms{frontier}}$.

Now we show that each vertex in this sequence $s$,
considered by A* in turn,
exists on OPEN with minimal $f$-value.
Iteratively consider the following procedure for sequence $s$.
Throughout,
we know that there must not be any vertex with
$f(v) < \ell^*_{\ms{lazy}}$,
that would imply that a different path through $v_b$ shorter than
$\ell^*_{\ms{lazy}}$ exists,
in which case $p^*_{\ms{lazy}}$ could not have been chosen.

If the sequence has length $>1$,
then consider the first two vertices on $s$, $v_a$ and $v_b$.
By construction,
$f(v_a) = \ell^*_{\ms{lazy}}$
and 
$f(v_b) \neq \ell^*_{\ms{lazy}}$.
In fact, from above
we know that $f(v_b) > \ell^*_{\ms{lazy}}$.
Therefore,
we have that $f(v_a) < f(v_b)$,
therefore and $g[v_a] + w(v_a,v_b) < g[v_b]$.
By Invariant~\ref{inv:astar-wless-popen},
$v_a$ must be on OPEN,
and with $f(v_a) = \ell^*_{\ms{lazy}}$,
it can therefore be considered by A*.
After it is expanded,
$f(v_b) = \ell^*_{\ms{lazy}}$,
and we can repeat the above procedure
with the sequence formed by removing the $v_a$ from $s$.

If instead the sequence has length $1$,
then it must be exactly $(v_{\ms{frontier}})$,
with $f(v_{\ms{frontier}}) = \ell^*_{\ms{lazy}}$.
Since the edge after $f(v_{\ms{frontier}})$ is not
evaluated,
then by Invariant~\ref{inv:astar-cundisc-popen},
$v_{\ms{frontier}}$ must be on OPEN,
and will therefore be expanded next.
\end{proof}

\begin{proof}[Proof of Theorem \ref{thm:astar-equiv-to-lazy}]
Given that all vertices in $s_{\ms{candidate}}$ besides the last
are re-expansions,
they can be expanded with no edge evaluations.
Once the last vertex,
$v_{\ms{frontier}}$,
is to be expanded by A*,
suppose it has $f$-value $\ell$.

First,
we will show that there exists a path with length $\ell$ w.r.t.
$w_{\ms{lazy}}$
wherein all edges before $v_{\ms{frontier}}$ have been evaluated,
and the first edge after $v_{\ms{frontier}}$ has not.
Let $p_a$ be a shortest path from $v_{\ms{start}}$
to $v_{\ms{frontier}}$ consisting of only evaluated edges.
The length of this $p_a$ must be equal to $g[v_{\ms{frontier}}]$;
if it were not,
there would be some previous vertex on $p_a$ with lower $f$-value
than $v_{\ms{frontier}}$,
which would necessarily have been expanded first.
Let $p_b$ be the a shortest path from $v_{\ms{frontier}}$
to $v_{\ms{goal}}$.
The length of $p_b$ must be $h_{\ms{lazy}}(v_{\ms{frontier}})$
by definition.
Therefore, the path $(p_a, p_b)$ must have length $\ell$,
and since $v_{\ms{frontier}}$ is a new expansion,
the first edge on $p_b$ must be unevaluated.

Second,
we will show that there does not exist any path shorter than $\ell$
w.r.t. $w_{\ms{lazy}}$.
Suppose $p'$ were such a path, with length $\ell' < \ell$.
Clearly, $v_{\ms{start}}$ would have $f$-value $\ell'$ (although
it may not be on OPEN).
Consider each pair of vertices $(v_a, v_b)$ along $p'$ in turn.
In each case,
if $v_b$ were either undiscovered,
or if $g[v_a] + w(v_a, v_b) < g[v_b]$,
then $v_a$ would be on OPEN
(via Invariants \ref{thm:lazy-completeness}
and \ref{inv:astar-wless-popen}, respectively)
with $f(v_a) = \ell'$,
and would therefore have been expanded before $v_{\ms{frontier}}$.
Otherwise,
we know that $f(v_b) = \ell'$,
and we can continue to the next pair on $p'$.
\end{proof}

\subsection{LWA* Equivalence}

\begin{proof}[Proof of Invariant \ref{inv:lwastar}]
Clearly the invariant holds at the beginning of the algorithm
with only $g[v_{\ms{start}}] = 0$,
since the inequality holds only for the out-edges of $v_{\ms{start}}$,
with $v_{\ms{start}}$ on $Q_v$.
Consider each subsequent iteration.
If a vertex $v$ is popped from $Q_v$,
then this may invalidate the invariant for all successors of $v$;
however,
since all out-edges are immediately added to $Q_e$,
the invariant must hold.
Consider instead if an edge $(v, v')$ which satisfies the inequality
is popped from $Q_e$.
Due to the inequality,
we know that $g[v']$ will be recalculated as
$g[v'] = g[v] + w(v,v')$,
so that the inequality is no longer satisfied for edge $(v,v')$.
However,
reducing the value $g[v']$ may introduce satisfied inequalities across
subsequent out-edges of $v'$,
but since $v'$ is added to $Q_v$,
the invariant continues to hold.
\end{proof}

\begin{proof}[Proof of Theorem \ref{thm:lwastar-equiv-from-lazy}]
In the first component of the equivalence,
we will show that for any path $p$ minimizing $w_{\ms{lazy}}$
allowable to LazySP-Forward,
with $(v_a, v_b)$ the first unevaluated edge on $p$,
there exists a sequence of vertices and edges on
$Q_v$ and $Q_e$ allowable to LWA*
such that edge $(v_a, v_b)$ is the first to be newly evaluated.
Let the length of $p$ w.r.t. $w_{\ms{lazy}}$ be $\ell$.'

We will first show that no vertex on $Q_v$ or edge on $Q_e$
can have $f(\cdot) < \ell$.
Suppose such a vertex $v$, or edge $e$ with source vertex $v$,
exists.
Then $g[v] + h(v) < \ell$,
and there must be some path $p'$ consisting of an evaluated segment
from $v_{\ms{start}}$ to $v$ of length $g[v]$,
followed a segment from $v$ to $v_{\ms{goal}}$ of length $h(v)$.
But then this path should have been chosen by LazySP.

Next, we will show a procedure for generating an allowable
sequence for LWA*.
We will iteratively consider a sequence of path segments,
starting with the segment from $v_{\ms{start}}$ to $v_a$,
and becoming progressively shorter at each iteration by removing the
first vertex and edge on the path.
We will show that the first vertex on each segment $v_f$
has $g[v_f] = \ell - h(v_f)$.
By definition,
this is true of the first such segment, since $g[v_{\ms{start}}] = 0$.
For each but the last such segment,
consider the first edge, $(v_f, v_s)$.
If $v_s$ has the correct $g[\cdot]$,
we can continue to the next segment immediately.
Otherwise,
either $v_f$ is on $Q_v$ or $(v_f, v_s)$ is on $Q_e$ by
Invariant~\ref{inv:lwastar}.
If the former is true,
then $v_f$ can be popped from $Q_v$ with $f = \ell$,
thereby adding $(v_f, v_s)$ to $Q_e$.
Then,
$(v_f, v_s)$ can be popped from $Q_e$ with $f = \ell$,
resulting in $g[v_s] = \ell - h(v_s)$.
We can then move on to the next segment.

At the end of this process,
we have the trivial segment $(v_a)$,
with $g[v_a] = \ell - h(v_a)$.
If $v_a$ is on $Q_v$, then pop it (with $f(v_a) = \ell$),
placing $e_{ab}$ on $Q_e$;
otherwise, since $e_{ab}$ is unevaluated,
it must already be on $Q_e$.
Since $f(e_{ab}) = \ell$, we can pop and evaluate it.
\end{proof}

\begin{proof}[Proof of Theorem \ref{thm:lwastar-equiv-to-lazy}]
Given that all vertices in $s_{\ms{candidate}}$ entail no edge evaluations,
and all edges therein are re-expansions,
they can be considered with no edge evaluations.
Once the last edge $e_{xy}$ is to be expanded by LWA*,
suppose it has $f$-value $\ell$.

First,
we will show that there exists a path with length $\ell$ w.r.t.
$w_{\ms{lazy}}$
which traverses unevaluated edge $e_{xy}$
wherein all edges before $v_x$ have been evaluated.
Let $p_x$ be a shortest path segment from $v_{\ms{start}}$
to $v_x$ consisting of only evaluated edges.
The length of $p_x$ must be equal to $g[v_x]$;
if it were not,
there would be some previous vertex on $p_x$ with lower $f$-value
than $v_x$,
which would necessarily have been expanded first.
Let $p_y$ be the a shortest path from $v_y$
to $v_{\ms{goal}}$.
The length of $p_y$ must be $h_{\ms{lazy}}(v_y)$
by definition.
Therefore, the path $(p_x, e_{xy}, p_y)$ must have length $\ell$.

Second,
we will show that there does not exist any path shorter than $\ell$
w.r.t. $w_{\ms{lazy}}$.
Suppose $p'$ were such a path, with length $\ell' < \ell$,
and with first unevaluated edge $e'_{xy}$.
Clearly, $v_{\ms{start}}$ has
$g[v_{\ms{start}}] = \ell' - h(v_{\ms{start}})$.
Consider each evaluated edge $e'_{ab}$ along $p'$ in turn.
In each case,
if $g[v'_b] \neq \ell' - h(v'_b)$,
then either $v'_a$ or $e'_{ab}$ would be on $Q_v$ or $Q_e$
with $f(\cdot) = \ell'$,
and would therefore be expanded before $e_{xy}$.
Therefore,
$e'_{xy}$ would then be popped from $Q_e$ with $f(e'_{xy}) = \ell'$,
and it would have been evaluated before $e_{xy}$ with $f(e_{xy}) = \ell$.
\end{proof}

\chapter{Appendix: LazySP Timing Results}
\label{sec:appendix-timing}

We include an accounting of the cumulative computation time taken by
each component of LazySP for each of the seven selectors
for each problem class (Figure~\ref{fig:table-timing-results}).

\begin{figure*}
   \begin{widepage}
   \centering
   {\small%
   \setlength{\tabcolsep}{0.06cm}%
   \begin{tabular}{l@{\hskip 9pt}rc@{\hskip 0pt}r@{\hskip 9pt}rc@{\hskip 0pt}r@{\hskip 9pt}rc@{\hskip 0pt}r@{\hskip 9pt}rc@{\hskip 0pt}r@{\hskip 9pt}rc@{\hskip 0pt}r@{\hskip 9pt}rc@{\hskip 0pt}r@{\hskip 9pt}rc@{\hskip 0pt}r}
      \toprule
         & \multicolumn{3}{c}{Expand} & \multicolumn{3}{c}{Forward} & \multicolumn{3}{c}{Reverse} & \multicolumn{3}{c}{Alternate}
         & \multicolumn{3}{c}{Bisect} & \multicolumn{3}{c}{WeightSamp} & \multicolumn{3}{c}{Partition} \\
      \midrule
      \addlinespace[0.5em]
      PartConn & & & & & & & & & & & & & & & & & & & & & \\
      \;\;\emph{total (ms)}    &\bf1.22 &$\pm$&   0.04 &    1.96 &$\pm$&  0.06 &    1.86 &$\pm$&  0.06 &\bf1.20 &$\pm$& 0.03 &  2.41 &$\pm$& 0.06 & 4807.19 &$\pm$& 135.22 &   15.81 &$\pm$&  0.16 \\
      \;\;\emph{sel-init (ms)} & --\;\; &     &        &  --\;\; &     &       &  --\;\; &     &       & --\;\; &     &      &--\;\; &     &      &  --\;\; &     &        &   12.49 &$\pm$&  0.11 \\
      \;\;\emph{online (ms)}   &\bf1.22 &$\pm$&   0.04 &    1.96 &$\pm$&  0.06 &    1.86 &$\pm$&  0.06 &\bf1.20 &$\pm$& 0.03 &  2.41 &$\pm$& 0.06 & 4807.19 &$\pm$& 135.22 &    3.32 &$\pm$&  0.10 \\
      \;\;\emph{search (ms)}   &   0.48 &$\pm$&   0.01 &    1.12 &$\pm$&  0.03 &    1.05 &$\pm$&  0.03 &   0.68 &$\pm$& 0.02 &  1.38 &$\pm$& 0.04 &    0.70 &$\pm$&   0.02 &    0.68 &$\pm$&  0.02 \\
      \;\;\emph{sel (ms)}      &   0.02 &$\pm$&   0.00 &    0.01 &$\pm$&  0.00 &    0.01 &$\pm$&  0.00 &   0.01 &$\pm$& 0.00 &  0.03 &$\pm$& 0.00 & 4805.64 &$\pm$& 135.18 &    2.07 &$\pm$&  0.06 \\
      \;\;\emph{eval (ms)}     & --\;\; &     &        &  --\;\; &     &       &  --\;\; &     &       & --\;\; &     &      &--\;\; &     &      &  --\;\; &     &        &  --\;\; &     &       \\
      \;\;\emph{eval (edges)}  &  87.10 &$\pm$&   2.39 &   35.86 &$\pm$&  1.04 &   34.84 &$\pm$&  1.04 &  22.23 &$\pm$& 0.60 & 44.81 &$\pm$& 1.11 &\bf20.66 &$\pm$&   0.57 &\bf20.39 &$\pm$&  0.56 \\
      \addlinespace[0.5em]
      UnitSquare & & & & & & & & & & & & & & & & & & & & & \\
      \;\;\emph{total (ms)}    &\bf0.91 &$\pm$&   0.03 &    1.47 &$\pm$&  0.06 &    1.49 &$\pm$&  0.06 &\bf0.94 &$\pm$& 0.03 &  1.71 &$\pm$& 0.04 & 3864.95 &$\pm$& 117.66 &   15.13 &$\pm$&  0.14 \\
      \;\;\emph{sel-init (ms)} & --\;\; &     &        &  --\;\; &     &       &  --\;\; &     &       & --\;\; &     &      &--\;\; &     &      &  --\;\; &     &        &   13.41 &$\pm$&  0.12 \\
      \;\;\emph{online (ms)}   &\bf0.91 &$\pm$&   0.03 &    1.47 &$\pm$&  0.06 &    1.49 &$\pm$&  0.06 &\bf0.94 &$\pm$& 0.03 &  1.71 &$\pm$& 0.04 & 3864.95 &$\pm$& 117.66 &    1.72 &$\pm$&  0.06 \\
      \;\;\emph{search (ms)}   &   0.35 &$\pm$&   0.01 &    0.79 &$\pm$&  0.03 &    0.82 &$\pm$&  0.03 &   0.51 &$\pm$& 0.02 &  0.92 &$\pm$& 0.02 &    0.75 &$\pm$&   0.02 &    0.45 &$\pm$&  0.01 \\
      \;\;\emph{sel (ms)}      &   0.01 &$\pm$&   0.00 &    0.01 &$\pm$&  0.00 &    0.01 &$\pm$&  0.00 &   0.01 &$\pm$& 0.00 &  0.02 &$\pm$& 0.00 & 3863.49 &$\pm$& 117.62 &    0.87 &$\pm$&  0.03 \\
      \;\;\emph{eval (ms)}     & --\;\; &     &        &  --\;\; &     &       &  --\;\; &     &       & --\;\; &     &      &--\;\; &     &      &  --\;\; &     &        &  --\;\; &     &       \\
      \;\;\emph{eval (edges)}  &  69.21 &$\pm$&   2.55 &   27.29 &$\pm$&  1.03 &   27.69 &$\pm$&  1.02 &  17.82 &$\pm$& 0.60 & 32.62 &$\pm$& 0.72 &   15.58 &$\pm$&   0.47 &\bf14.08 &$\pm$&  0.46 \\
      \addlinespace[0.5em]
      ArmPlan (avg) & & & & & & & & & & & & & & & & & & & & & \\
      \;\;\emph{total (s)}    &  269.82 &$\pm$&  17.95 &\bf 5.90 &$\pm$&  0.46 &    8.22 &$\pm$&  0.53 &\bf5.96 &$\pm$& 0.31 &  7.34 &$\pm$& 0.43 & 3402.21 &$\pm$& 172.20 &  496.57 &$\pm$&  5.53 \\
      \;\;\emph{sel-init (s)} &  --\;\; &     &        &  --\;\; &     &       &  --\;\; &     &       & --\;\; &     &      &--\;\; &     &      &  --\;\; &     &        &  490.77 &$\pm$&  5.51 \\
      \;\;\emph{online (s)}   &  269.82 &$\pm$&  17.95 &\bf 5.90 &$\pm$&  0.46 &    8.22 &$\pm$&  0.53 &\bf5.96 &$\pm$& 0.31 &  7.34 &$\pm$& 0.43 & 3402.21 &$\pm$& 172.20 &\bf 5.80 &$\pm$&  0.28 \\
      \;\;\emph{search (s)}   &    0.02 &$\pm$&   0.00 &    0.02 &$\pm$&  0.00 &    0.02 &$\pm$&  0.00 &   0.02 &$\pm$& 0.00 &  0.02 &$\pm$& 0.00 &    0.02 &$\pm$&   0.00 &    0.04 &$\pm$&  0.00 \\
      \;\;\emph{sel (s)}      &    0.00 &$\pm$&   0.00 &    0.00 &$\pm$&  0.00 &    0.00 &$\pm$&  0.00 &   0.00 &$\pm$& 0.00 &  0.00 &$\pm$& 0.00 & 3392.76 &$\pm$& 171.74 &    1.54 &$\pm$&  0.09 \\
      \;\;\emph{eval (s)}     &  269.78 &$\pm$&  17.95 &    5.87 &$\pm$&  0.45 &    8.20 &$\pm$&  0.52 &   5.94 &$\pm$& 0.31 &  7.31 &$\pm$& 0.43 &    9.39 &$\pm$&   0.57 &    4.21 &$\pm$&  0.22 \\
      \;\;\emph{eval (edges)} &  949.05 &$\pm$&  63.46 &   63.62 &$\pm$&  4.15 &   74.94 &$\pm$&  5.07 &  55.48 &$\pm$& 2.95 & 68.01 &$\pm$& 3.86 &   56.93 &$\pm$&   3.37 &\bf48.07 &$\pm$&  2.44 \\
      \addlinespace[0.25em]
      ArmPlan1 & & & & & & & & & & & & & & & & & & & & & \\
      \;\;\emph{total (s)}    &  109.09 &$\pm$&  14.15 &\bf 4.81 &$\pm$&  0.49 &   14.81 &$\pm$&  1.45 &   7.03 &$\pm$& 0.63 &  7.91 &$\pm$& 0.70 & 3375.35 &$\pm$& 319.81 &  496.74 &$\pm$&  8.22 \\
      \;\;\emph{sel-init (s)} &  --\;\; &     &        &  --\;\; &     &       &  --\;\; &     &       & --\;\; &     &      &--\;\; &     &      &  --\;\; &     &        &  489.49 &$\pm$&  8.18 \\
      \;\;\emph{online (s)}   &  109.09 &$\pm$&  14.15 &\bf 4.81 &$\pm$&  0.49 &   14.81 &$\pm$&  1.45 &   7.03 &$\pm$& 0.63 &  7.91 &$\pm$& 0.70 & 3375.35 &$\pm$& 319.81 &    7.25 &$\pm$&  0.66 \\
      \;\;\emph{search (s)}   &    0.02 &$\pm$&   0.00 &    0.02 &$\pm$&  0.00 &    0.03 &$\pm$&  0.00 &   0.02 &$\pm$& 0.00 &  0.02 &$\pm$& 0.00 &    0.02 &$\pm$&   0.00 &    0.04 &$\pm$&  0.00 \\
      \;\;\emph{sel (s)}      &    0.00 &$\pm$&   0.00 &    0.00 &$\pm$&  0.00 &    0.00 &$\pm$&  0.00 &   0.00 &$\pm$& 0.00 &  0.00 &$\pm$& 0.00 & 3358.82 &$\pm$& 318.17 &    1.61 &$\pm$&  0.16 \\
      \;\;\emph{eval (s)}     &  109.07 &$\pm$&  14.15 &    4.78 &$\pm$&  0.49 &   14.77 &$\pm$&  1.44 &   7.01 &$\pm$& 0.63 &  7.88 &$\pm$& 0.70 &   16.47 &$\pm$&   1.68 &    5.59 &$\pm$&  0.51 \\
      \;\;\emph{eval (edges)} &  344.74 &$\pm$&  39.63 &\bf49.72 &$\pm$&  4.25 &   95.58 &$\pm$&  9.67 &  59.44 &$\pm$& 5.06 & 58.90 &$\pm$& 4.74 &   73.72 &$\pm$&   7.63 &\bf50.66 &$\pm$&  4.43 \\
      \addlinespace[0.25em]
      ArmPlan2 & & & & & & & & & & & & & & & & & & & & & \\
      \;\;\emph{total (s)}    &  166.19 &$\pm$&   9.29 &\bf 3.27 &$\pm$&  0.25 &    7.36 &$\pm$&  0.69 &   5.95 &$\pm$& 0.52 &  5.63 &$\pm$& 0.45 & 4758.04 &$\pm$& 407.56 &  495.21 &$\pm$& 12.65 \\
      \;\;\emph{sel-init (s)} &  -    - &     &        &  --\;\; &     &       &  --\;\; &     &       & --\;\; &     &      &--\;\; &     &      &  --\;\; &     &        &  489.22 &$\pm$& 12.64 \\
      \;\;\emph{online (s)}   &  166.19 &$\pm$&   9.29 &\bf 3.27 &$\pm$&  0.25 &    7.36 &$\pm$&  0.69 &   5.95 &$\pm$& 0.52 &  5.63 &$\pm$& 0.45 & 4758.04 &$\pm$& 407.56 &    5.99 &$\pm$&  0.48 \\
      \;\;\emph{search (s)}   &    0.01 &$\pm$&   0.00 &    0.01 &$\pm$&  0.00 &    0.02 &$\pm$&  0.00 &   0.01 &$\pm$& 0.00 &  0.01 &$\pm$& 0.00 &    0.02 &$\pm$&   0.00 &    0.03 &$\pm$&  0.00 \\
      \;\;\emph{sel (s)}      &    0.00 &$\pm$&   0.00 &    0.00 &$\pm$&  0.00 &    0.00 &$\pm$&  0.00 &   0.00 &$\pm$& 0.00 &  0.00 &$\pm$& 0.00 & 4750.16 &$\pm$& 406.98 &    2.03 &$\pm$&  0.22 \\
      \;\;\emph{eval (s)}     &  166.17 &$\pm$&   9.28 &\bf 3.26 &$\pm$&  0.25 &    7.34 &$\pm$&  0.69 &   5.93 &$\pm$& 0.52 &  5.61 &$\pm$& 0.45 &    7.82 &$\pm$&   0.61 &    3.91 &$\pm$&  0.27 \\
      \;\;\emph{eval (edges)} &  657.02 &$\pm$&  29.24 &\bf62.24 &$\pm$&  6.12 &   98.54 &$\pm$& 10.89 &  69.96 &$\pm$& 6.98 & 75.88 &$\pm$& 7.47 &\bf66.24 &$\pm$&   6.36 &\bf62.16 &$\pm$&  6.10 \\
      \addlinespace[0.25em]
      ArmPlan3 & & & & & & & & & & & & & & & & & & & & & \\
      \;\;\emph{total (s)}    &  534.16 &$\pm$&  55.64 &    9.61 &$\pm$&  1.33 &\bf 2.50 &$\pm$&  0.23 &   4.91 &$\pm$& 0.56 &  8.47 &$\pm$& 0.99 & 2073.23 &$\pm$& 198.75 &  497.76 &$\pm$& 10.27 \\
      \;\;\emph{sel-init (s)} &  --\;\; &     &        &  --\;\; &     &       &  --\;\; &     &       & --\;\; &     &      &--\;\; &     &      &  --\;\; &     &        &  493.59 &$\pm$& 10.21 \\
      \;\;\emph{online (s)}   &  534.16 &$\pm$&  55.64 &    9.61 &$\pm$&  1.33 &\bf 2.50 &$\pm$&  0.23 &   4.91 &$\pm$& 0.56 &  8.47 &$\pm$& 0.99 & 2073.23 &$\pm$& 198.75 &    4.17 &$\pm$&  0.43 \\
      \;\;\emph{search (s)}   &    0.02 &$\pm$&   0.01 &    0.02 &$\pm$&  0.00 &    0.02 &$\pm$&  0.00 &   0.02 &$\pm$& 0.00 &  0.02 &$\pm$& 0.00 &    0.03 &$\pm$&   0.01 &    0.04 &$\pm$&  0.00 \\
      \;\;\emph{sel (s)}      &    0.00 &$\pm$&   0.00 &    0.00 &$\pm$&  0.00 &    0.00 &$\pm$&  0.00 &   0.00 &$\pm$& 0.00 &  0.00 &$\pm$& 0.00 & 2069.29 &$\pm$& 198.53 &    0.98 &$\pm$&  0.13 \\
      \;\;\emph{eval (s)}     &  534.10 &$\pm$&  55.63 &    9.58 &$\pm$&  1.33 &    2.48 &$\pm$&  0.23 &   4.89 &$\pm$& 0.56 &  8.44 &$\pm$& 0.99 &    3.90 &$\pm$&   0.31 &    3.15 &$\pm$&  0.32 \\
      \;\;\emph{eval (edges)} & 1845.38 &$\pm$& 195.57 &   78.90 &$\pm$& 10.36 &\bf30.70 &$\pm$&  3.62 &  37.04 &$\pm$& 4.59 & 69.26 &$\pm$& 7.97 &\bf30.82 &$\pm$&   3.60 &\bf31.38 &$\pm$&  3.80 \\
      \addlinespace[0.25em]
      \bottomrule
   \end{tabular}%
   }%
   \end{widepage}
   \vspace{0.5cm}
   \caption{
      Detailed timing results for each selector.
      The actual edge weights for the illustrative
      PartConn and UnitSquare problems were pre-computed,
      and therefore their timings are not included.
      The Partition selector requires initialization of the $Z$-values
      (\ref{eqn:partitionfn}) for the graph using only the estimated
      edge weights.
      Since this is not particular to either the actual edge weights
      (e.g. from the obstacle distribution)
      or the start/goal vertices from a particular instance,
      this initialization (\emph{sel-init}) is considered separately.
      The online running time (\emph{online}) is broken into LazySP's
      three primary steps: the inner search (\emph{search}),
      invoking the edge selector (\emph{sel}),
      and evaluating edges (\emph{eval}).
      We also show the number of edges evaluated.}
   \label{fig:table-timing-results}
\end{figure*}




%\include{ch01-intro}
%\include{chxx-proposed-framework}
%\include{ch11-proposed}

\bibliographystyle{abbrv}
\bibliography{references}

\end{document}
